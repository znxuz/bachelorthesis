% TODO: check
\section{Implementierung für die Echtzeitanalyse}

Nachdem die Steuerungssoftware auf zwei verschiedenen Architekturen, nämlich
FreeRTOS und Micro-ROS, entwickelt wurde, kann nun eine konkrete
Implementierung einer Methode zur Analyse der Echtzeitfähigkeit basierend auf
FreeRTOS erfolgen, um die Portabilität auf Micro-ROS zu ermöglichen. Ziel der
Analyse ist es, Informationen darüber zu gewinnen, wie lange eine bestimmte Task
oder eine bestimmte zeitkritische Funktion benötigt. Die daraus resultierenden
Daten müssen mit einer angemessenen Genauigkeit erfasst werden, um
sicherzustellen, dass die Echtzeitaspekte korrekt widergespiegelt werden.

Aufgrund von Einfachheit sowie Hardwarebeschränkungen wurde UART als
Kommunikationsschnittstelle zur Übertragung der Echtzeitdaten vom
Mikrocontroller zum Host gewählt. Mit einer theoretischen Übertragungsrate von
bis zu 12,5 Mbit/s bietet UART ausreichende Bandbreite~\cite[S.
2]{stm32_datasheet}, um die Profiling-Daten zu übertragen, ohne Überlastung zu
verursachen.

der ansatz beruht darauf, dass zu begin und am Ende der jeweiligen Task
sowie der zeitkritischen Funktion die aktuelle Zyklenzahl aufzuzeichnen, um
daraus die Echtzeitinformationen abzuleiten.

Daraus ergibt sich als Erstes die Notwendigkeit, eine threadsichere Multi
Producer Senke, oder besser gesagt eine \ac{MPSC} Queue, zu implementieren,
welche die Echtzeitdaten kontinuierlich konsumiert und sie über UART ausgibt.
Die FreeRTOS Stream- oder Messagebuffer sind für den Fall mit mehreren Producers
nicht geeignet~\cite{FreeRTOSStreamBuffer}.

\subsection{Multi-Producer-Senke}

Da FreeRTOS und dementsprechend auch Micro-ROS von Natur aus multithreaded sind
und zur Echtzeitanalyse Daten von beliebiger Stelle in einem beliebigen Thread
beim Programmlauf aufgezeichnet werden, muss dabei die Threadsicherheit
gewährleistet werden, damit die zu übertragenden Daten in Form von mehreren
Bytes nicht durch Race Conditions teils überschrieben und zu unbrauchbaren Daten
werden.

Die grundlegende Idee besteht darin, dass Daten von mehreren Threads direkt in
die Senke gepusht, oder besser gesagt direkt in einen internen Ringpuffer
gespeichert werden, da das Schreiben der Daten in einen statischen
Speicherpuffer wesentlich schneller ist in comparison to enqueueing the data
into a linked list, because the latter requires dynamic heap memory allocation
which costs hundreds of cycles each per syscall, where as writing to a
In-Memory-Puffer with byte alignment typischerweise $N$ zyklen kostet wobei $N$
die anzahl der Bytes ist und der schreibvorgang deterministisch ist.

Da der Speicher begrenzt ist, muss die Senke im schlimmsten Fall in der Lage
sein zu erkennen, wann sie das weitere Schreiben von Daten in den Puffer
blockieren muss, um zu verhindern, dass zuvor geschriebene, aber noch nicht
verarbeitete Daten überschrieben werden.

Aber durch die Verwendung von DMA kombiniert mit einem Interrupt ausgelöst bei
jedem Abschluss einer DMA-Übertragung kann die IO-gebundene Wartezeit zum
Konsumieren der Bytes in der Senke eliminiert werden, da in diesem Fall die
tatsächliche Ausgabe von Daten aus der Senke einfach zum Schreiben in einen
anderen In-Memory-Puffer wird, während die eigentlichen IO-Operationen auf den
DMA-Controller fern vom Prozessor ausgelagert werden. Wenn die tatsächliche IO
die Daten schnell genug überträgt, um mit den eingehenden Daten Schritt zu
halten, entsteht dabei keine Situation, in der eine Task blockiert werden muss,
dass die Senke Speicherplatz freigibt, um den Schreibvorgang fortzusetzen.

Daher wurde als Ansatz mit der Umsetzung mit einer Multi-Producer-Senke mittels
DMA fortgefahren, da in diesem Fall das Schreiben von mehreren Bytes in die
Senke idealerweise nur einige Zyklen kosten und würde sich nahezu als eine
nicht-blockierende Operation vom Sicht des Prozessors oder Threads verhalten.

\subsubsection{Aufbau der Multi-Producer-Senke}

Wie kurz erwähnt, besteht die Senke einfacherweise hauptsächlich aus einem
statisch vorallokierten Ringpuffer gepaart mit einem Schreib- und Lesezeiger.
Mit den beiden Zeigern wird dann ermöglicht, die Größe der bereits geschriebenen
Daten sowie der restliche verfügbare Speicherplatz zu ermitteln.

In der ersten Version der Implementierung wurde die Anzahl der Daten in der
Senke so kalkuliert, dass wenn sich der Schreibzeiger beziehungsweise der Index
im numerischen Sinne vor dem Lesezeiger befindet, ist die Anzahl von
verbrauchbaren Daten einfach die Differenz von den beiden Indexen, ansonsten
sind die zu verarbeiteten Daten von dem Lesezeiger bis zum Ende des Ringpuffers
inklusive die Daten vom Anfang des Puffers bis zum Schreibzeiger, da die Zeiger
immer auch auf die korrekte Position zeigen.

Dabei muss aber zwischen dem Fall unterschieden werden, wenn beide Zeiger
gleichzeitig auf dieselbe Position zeigen: entweder ist der Ringpuffer leer,
oder komplett voll beschrieben. Also muss der Schreiber noch wissen, ob das
aktuelle Byte bereits verbraucht wurde und deshalb überschrieben werden kann, da
er sonst in keiner Weise unterscheiden kann, ob die Senke voll ist und dann das
Schreiben verzögern soll.

Inspiriert von einem C++-Konferenzvortrag über eine
\ac{MPMC}-Warteschlange~\cite{CppCon2024LockFreeQueue}, in dem jede Position des
Datenpuffers eine eindeutige Schreibsequenznummer besitzt, diese bei der
Entnahme der Daten atomar um die Gesamtlänge des Datenpuffers $N$ erhöht,
wodurch signalisiert wird, dass die Daten an dieser Position bereits in der
Iteration $N$ verarbeitet wurden und somit einwandfrei in der nächsten Iteration
$N + 1$ vom Schreiber überschrieben werden können, was durch den Vergleich mit
der globalen Schreibsequenznummer ermöglicht wird, die ebenfalls nach jedem
Schreibvorgang atomar erhöht wird.

Für den Fall mit einer Senke mit aber nur einem einzigen Verbraucher reicht es
aus, den Zustand als \mintinline{cpp}|bool| zu speichern, der angibt, ob die
Daten an einer bestimmten Position noch verarbeitet werden müssen oder bereits
überschrieben werden können.

Um diese zusätzliche Speicheranforderung verursacht durch das explizites
Markieren des Zustands für jedes Byte in dem Puffer für die finale
Implementierung wegzuoptimieren, brauchen die Zeiger nicht mehr immer auf die
korrekte Stelle zeigen, stattdessen können sie einfach über den Puffer hinaus
zählen und bei jeder Nutzung der Zeiger deren Wert mittels einer
Modulo-Operation mit der Gesamtgröße des Puffer normalisieren, so dass sie dann
auf die tatsächliche Stelle zeigen. Dadurch kann die Kalkulation für die Anzahl
der verfügbaren Daten auf eine simple Subtraktion zwischen den beiden Zeigern
reduziert werden. Wenn die Größe des Puffers a power of two entspricht, kann die
Kosten der Modulo-Operation auf ein Zyklus reduziert werden, which is a good
trade-off and a small price to pay for eliminating the need for extra speicher
space for the Zustand.

\begin{code}
\begin{minted}{cpp}
#ifndef TSINK_CAPACITY
constexpr size_t TSINK_CAPACITY = 2048;
#endif
uint8_t sink[TSINK_CAPACITY]{};
volatile size_t read_idx = 0;
std::atomic<size_t> write_idx = 0;

size_t size() { return write_idx - read_idx; }
size_t space() { return TSINK_CAPACITY - size(); }
size_t normalize(size_t idx) { return idx % TSINK_CAPACITY; }
\end{minted}
    \captionof{listing}{Struktur der Senke}
\end{code}

\subsubsection{Schreibvorgang in die Senke}

Auf ARM-Architekturen sind alle Zugriffe auf im Speicher ausgerichteten Bytes,
Halbwörter (16-Bit) und Wörter (32-Bit) standardmäßig atomar und verursachen
keine Schreib-Lese-Konflikte, sowohl beim Lesen als auch beim Schreiben~\cite[S.
A3-79]{ARM_DDI0403_EE}.

Es muss jedoch sichergestellt werden, dass jeweils nur exakt ein einziger Thread
an eine Position des Ringpuffers schreiben kann, wenn mehrere Threads
gleichzeitig auf dieselbe Position zugreifen wollen.

Anbei kann eine \ac{CAS}-Operation durchgeführt werden, damit der Schreibindex
bei gleichzeitigen Zugriffen von mehreren Threads immer nur von einem einzigen
Thread inkrementiert wird. Nach der Inkrementierung hat somit der Thread den
Anspruch, das Byte mit dem vorherigen Index zu schreiben, welcher den Index
erfolgreich inkrementiert hat.

\begin{code}
\begin{minted}{cpp}
bool write_or_fail(uint8_t elem) {
  auto expected = write_idx.load();
  if (expected - read_idx == TSINK_CAPACITY) return false;
  if (write_idx.compare_exchange_strong(expected, expected + 1)) {
    sink[normalize(expected)] = elem;
    return true;
  }
  return false;
}
\end{minted}
    \captionof{listing}{atomare Schreiboperation in die Senke}
\end{code}

Die Vorgehensweise ist wie folgt: zuerst wird der aktuelle Schreibindex als
lokale Variable \mintinline{cpp}|expected| zwischengespeichert und es wird damit
überprüft, ob der Puffer bereits voll ist und liefert vorzeitig zurück wenn dies
der Fall ist, sonst bedeutet es, dass die Position mit dem aktuellen Index zu
dieser Zeit noch beschreibbar ist. Danach wird die atomare CAS-Operation
durchgeführt, indem der Schreibindex mit dem zwischengespeicherten Wert
vergleicht und gleichzeitig um eins inkrementiert wird, wenn die beiden Werten
derselbe sind. Die Fähigkeit, den Vergleich und auch den darauffolgenden
Inkrement unter der Voraussetzung von Äquivalenz alle zusammen als eine atomare
Operation durchführen zu können, ermöglicht, dass nur ein Thread am Ende den
Schreibindex erfolgreich inkrementieren und folglich Daten über den
zwischengespeicherten Index schreiben kann. Dabei wird die Synchonisation also
in einer nicht-blockierenden Weise (lock-free) garantiert.

Um das Schreiben von mehreren Bytes auch threadsicher durchzuführen, muss dabei
ein Mutex eingesetzt werden~\cite{FreeRTOSForumPrintf}. Dies stellt sicher im
Vergleich zu einem einfach Semaphor, dass ein Thread, der ein Mutex hält, es
möglichst schnell wieder freigibt und auch niemals vom Scheduler ausgeschlossen
wird (\ref{sec:mutex}).

Die Definition des Struktuertyps \mintinline{cpp}|struct mtx_guard| ist hier
implementiert. Dieser beruht auf \ac{RAII}, um beim Erstellen eines Objekts
automatisch den Mutex zu sperren und ihn erst bei Verlassen des
Gültigkeitsbereichs – in diesem Fall beim Verlassen des
\mintinline{cpp}|if|-Blocks – wieder freizugeben.

\begin{code}
\begin{minted}{cpp}
struct mtx_guard {
  mtx_guard() { configASSERT(xSemaphoreTake(write_mtx, portMAX_DELAY)); }
  ~mtx_guard() { configASSERT(xSemaphoreGive(write_mtx)); }
};

void write_blocking(const uint8_t* ptr, size_t len) {
  while (true) {
    if (volatile auto _ = mtx_guard{}; space() >= len) {
      for (size_t i = 0; i < len; ++i) configASSERT(write_or_fail(ptr[i]));
      return;
    }
    vTaskDelay(pdMS_TO_TICKS(1));
  }
}
\end{minted}
    \captionof{listing}{Blockierende Schreiboperation in die Senke}
\end{code}

\subsubsection{Lesevorgang aus der Senke}

Eine kleine, statisch allokierte FreeRTOS-Task wird erstellt, um kontinuierlich
zu versuchen, verfügbare Daten aus der Senke zu entnehmen und verarbeiten.

\begin{code}
\begin{minted}{cpp}
using consume_fn = void (*)(const uint8_t*, size_t);
consume_fn consume;

void task_impl(void*) {
  auto consume_and_wait = [](size_t pos, size_t size) static {
    if (!size) return;
    consume(sink + pos, size);
    ulTaskNotifyTake(pdFALSE, portMAX_DELAY);
  };

  while (true) {
    if (size_t sz = size(); sz) {
      auto wrap_around = ((normalize(read_idx) + sz) / TSINK_CAPACITY) *
                         normalize(read_idx + sz);
      auto immediate = sz - wrap_around;
      consume_and_wait(normalize(read_idx), immediate);
      consume_and_wait(0, wrap_around);
      read_idx += sz;
    } else {
      vTaskDelay(pdMS_TO_TICKS(1));
    }
  }
}
\end{minted}
    \captionof{listing}{Implementierung der Task zur Datenverarbeitung}
\end{code}

Als Verbrauchsfunktion \mintinline{cpp}|consume()| kann beispielsweise die
STM32-HAL-API zur Übertragung mittels DMA genutzt werden, welche einen Zeiger
zu einem Array und eine Variable als die Größe der lesbaren Daten als Parameter
einnimmt.

Hierbei wird zuerst die Größe von möglichen verfügbaren Daten vom Anfang des
Ringpuffers bis zur dem Schreibindex mathematisch kalkuliert und damit auch die
Größe vom Leseindex bis zum Ende des Puffers. Mit jedem Aufruf von
\mintinline{cpp}|consume()| wird mit \mintinline{cpp}|ulTaskNotifyTake()| darauf
gewartet, dass die aktuelle IO-Operation fertig wird und somit neue Operation
durchführen kann. Diese Vorgehensweise ist notwendig wenn
\mintinline{cpp}|consume()| beispielsweise DMA nutzt: Die DMA-API von der
STM32-HAL zur Übertragung ist möglicherweise nicht wiedereintrittsfähig und
signalisiert dabei lediglich der Hardware den gewünschten Transfervorgang und
kehrt sofort zurück \cite{HAL_UART_Transmit_DMA}. Das heißt, die Daten werden
einfach zur Verarbeitung für den DMA eingereiht, während der Programmfluss
unmittelbar fortgesetzt wird. Daher werden subsequente Aufrufe hierbei
synchronisiert.

\begin{code}
\begin{minted}{cpp}
enum struct CALL_FROM { ISR, NON_ISR };

template <CALL_FROM callsite>
void consume_complete() {
  using namespace detail;
  if constexpr (callsite == CALL_FROM::ISR) {
    static BaseType_t xHigherPriorityTaskWoken;
    vTaskNotifyGiveFromISR(task_hdl, &xHigherPriorityTaskWoken);
    portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
  } else {
    xTaskNotifyGive(task_hdl);
  }
}
\end{minted}
    \captionof{listing}{Callback-Funktion für die Task-Notification}
\end{code}

Erst nachdem die Task-Notifikation durch den Aufruf von
\mintinline{cpp}|consume_complete()| empfangen wird, beispielsweise von einer
\ac{ISR}, die durch die DMA-Hardware nach Abschluss der Übertragung ausgelöst
wird, wird die Task wieder entblockt um weitere IO-Operationen zu beauftragen.

\subsubsection{Nutzung der Senke mit DMA}

Um diese Senke mit DMA und aktiviertem Daten-Cache zu verwenden, muss zunächst
die Interrupt-Callback \mintinline{cpp}|HAL_UART_TxCpltCallback()| definiert
werden, die bei Abschluss jedes DMA-Transfers ausgelöst wird.

Die Initialisierungsfunktion der Senke ist dann aufzurufen, welche einen
Funktionszeiger vom Typ \mintinline{cpp}|consume_fn| zur Verarbeitung von
Daten~(\ref{code:cache_clean}) von Daten sowie eine Priorität für die interne
Verbraucher-Task als Argumente entgegennehmen.

\begin{code}
\begin{minted}{cpp}
void HAL_UART_TxCpltCallback(UART_HandleTypeDef* huart) {
  if (huart->Instance == huart3.Instance)
    tsink::consume_complete<tsink::CALL_FROM::ISR>();
}

void main() {
  auto tsink_consume_dma = [](const uint8_t* buf, size_t size) static {
    auto flush_cache_aligned = [](uintptr_t addr, size_t size) static {
      constexpr auto align_addr = [](uintptr_t addr) { return addr & ~0x1F; };
      constexpr auto align_size = [](uintptr_t addr, size_t size) {
        return size + ((addr) & 0x1F);
      };

      SCB_CleanDCache_by_Addr(reinterpret_cast<uint32_t*>(align_addr(addr)),
                              align_size(addr, size));
    };

    flush_cache_aligned(reinterpret_cast<uintptr_t>(buf), size);
    HAL_UART_Transmit_DMA(&huart3, buf, size);
  };
  tsink::init(tsink_consume_dma, osPriorityAboveNormal);
}
\end{minted}
    \captionof{listing}{Initialisierung der Senke mit DMA}
\end{code}

\subsubsection{Nutzung der Senke mit blockierender IO}

Ähnlich wie bei der Initialisierung über DMA, entfällt hier aber der
Interrupt-Callback, und die Funktion zur Datenverarbeitung wird durch die
Verwendung der blockierenden API ohne Leerung von Cache vereinfacht, da ohne DMA
keine manuelle Sicherstellung der Cache-Kohärenz notwendig ist.

\begin{code}
\begin{minted}{cpp}
int main() {
  auto tsink_consume = [](const uint8_t* buf, size_t size) static {
    HAL_UART_Transmit(&huart3, buf, size, HAL_MAX_DELAY);
    tsink::consume_complete<tsink::CALL_FROM::NON_ISR>();
  };

  tsink::init(tsink_consume, osPriorityAboveNormal);
}
\end{minted}
    \captionof{listing}{Initialisierung der Senke mit blockierender IO}
\end{code}

\subsubsection{Benchmark}

Ein Benchmark für die Senke wurde entwickelt, um deren Leistung unter paralleler
Last zu testen. Der Benchmark lässt eine Anzahl von
\mintinline{text}|BENCHMARK_N = 5| Threads gleichzeitig laufen, die jeweils eine
Anzahl von \mintinline{cpp}|iteration = 5000| Nachrichten mit ca. 80 Charaktern
nach Formatierung hintereinander über die Senke ausgeben.

Nach Abschluss des Benchmarks werden die gemessenen Zeiten und die
Laufzeitstatistiken der jeweiligen Task ausgegeben.

\begin{minipage}[t]{0.5\textwidth}
    \begin{code}
        \begin{minted}[linenos=false]{cpp}
time in ms: 8543
time in ms: 8728
time in ms: 9196
time in ms: 9342
time in ms: 9571
===================================
Task            Time            %%
print_bench     1               <1%
Tmr Svc         0               <1%
IDLE            72753           76%
benchmark       4363            4%
benchmark       4377            4%
benchmark       4257            4%
benchmark       4443            4%
benchmark       4238            4%
tsink           351             <1%
    \end{minted}
        \captionof{listing}{Benchmark DMA}
    \end{code}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
    \begin{code}
        \begin{minted}[linenos=false]{cpp}
time in ms: 10964
time in ms: 11016
time in ms: 11285
time in ms: 11379
time in ms: 11405
===================================
Task            Time            %%
print_bench     0               <1%
Tmr Svc         0               <1%
IDLE            0               <1%
benchmark       3624            3%
benchmark       3637            3%
benchmark       3623            3%
benchmark       3644            3%
benchmark       3631            3%
tsink           94876           83%
    \end{minted}
        \captionof{listing}{Benchmark mit blockierender IO}
    \end{code}
\end{minipage}

Die Ausgabe enthält zwei verschiedene Zeitmessungen für den Benchmark. Die erste
Messung erfasst die Zeitspanne vom Start des jeweiligen Threads bis zu dessen
Beendigung. Die zweite Messung bezieht sich auf die
FreeRTOS-Laufzeitstatistiken, die durch \mintinline{cpp}|vTaskGetRunTimeStats()|
formattiert ausgegeben werden. Diese liefern die absolute akkumulierte Zeit für
jede Task, die im Zustand „Running” verbracht hat, sowie deren prozentualen
Anteil an der Gesamtlaufzeit \cite{freertos_runtime_stats}.

Der Benchmark zeigt, dass asynchrone Übertragung per DMA die Gesamtlaufzeit des
Benchmark-Prozesses im Vergleich zur IO-gebundenen Variante um etwa $16\,\%$
verringerte, während gleichzeitig die IO-gebundene Zeit freigegeben wurde,
sodass sie von anderen Aufgaben genutzt werden kann.

Ebenso kann abgeleitet werden, dass durch die Verwendung von DMA die
Datenübertragungsrate nahezu das vorkonfigurierte Maximum der Baudrate von
$2.000.000\text{ bps}$ erreicht wurde. Insgesamt wurden $1.908.759$ Bytes
übertragen, dabei hat ein UART-Byte-Frame eine standardmäßige Wortlänge von 8
Bit hat, inklusive je 1 Start- und 1 Stopp-Bit, ohne Paritätsbit.

\begin{align*}
    1.908.355\text{\,B} \times 10\text{\,b per Frame} =
    19.083.550 \text{\,b} = \text{Gesamte Bits}
\end{align*}

Teilt man dies durch die gesamte Übertragungszeit, ergibt sich die effektive
Bitrate sowie der prozentuale Anteil im Vergleich zur maximalen Baudrate:

\begin{align*}
    \text{Bitrate bei DMA} =
    \frac{19.083.550\text{\,b}}{9,571\text{\,s}} \approx
    1.993.893,01 \text{\,bps} \\
    \quad \Rightarrow 99,70\,\%\text{ des Maximums} \\
    \\
    \text{Bitrate bei blockierender IO} =
    \frac{19.083.550\text{\,b}}{11,405\text{\,s}} \approx
    1.673.261,73 \text{\,bps} \\
    \quad \Rightarrow 83,66\,\% \text{ des Maximums}
\end{align*}

Der Code für die Senke sowie den Benchmark befinden sich in den
Repositorys~\cite{freertos_threadsafe_sink, freertos_tsink_benchmark}.

\subsection{Aktivierung der DWT}

Nachdem die threadsichere Datenausgabe implementiert wurde, kann nun die Frage
geklärt werden, wie die Dauer eines beliebigen Funktionsaufrufs oder einer
FreeRTOS-Task ab dem Start bis zum Abschluss einer Ausführungsabschnitts
gemessen werden kann.

Wie im vorherigen Abschnitt erläutert \ref{sec:dwt}, stellt die DWT als eine
geeignete Methode zur Generierung von Echtzeitdaten in Form von Zyklenzahl dar.
Sie ist standardmäßig auf Cortex-M7-Prozessoren verfügbar und kann durch die
folgenden Konfigurationsschritte aktiviert werden:

\begin{code}
\begin{minted}{cpp}
void enable_dwt() {
  CoreDebug->DEMCR |= CoreDebug_DEMCR_TRCENA_Msk;
  DWT->LAR = 0xC5ACCE55;  // software unlock
  DWT->CYCCNT = 1;
  DWT->CTRL |= DWT_CTRL_CYCCNTENA_Msk;
}
\end{minted}
    \captionof{listing}{Aktivierung der DWT \cite{StackOverflow_DWT_Activation}}
\end{code}

Danach kann die aktuelle Zyklenzahl direkt über \mintinline{cpp}|DWT->CYCCNT|
ausgelesen werden.

\subsection{Aufzeichnung von Zyklenstempeln}

Drei wesentliche Informationen werden bei der Aufzeichnung von Zyklenstempeln
erfasst: der Identifikator der zugehörigen Task oder Funktion, der aktuelle
Zyklenzahl und ein Marker, der angibt, ob der Zyklenstempel den Beginn oder das
Ende einer Dauer markiert. Diese Daten werden in einem Strukturtyp gespeichert.

\begin{code}
\begin{minted}{cpp}
struct cycle_stamp {
  const char* name;
  size_t cycle;
  bool is_begin;

  static inline uint32_t initial_cycle = 0;
};
\end{minted}
    \captionof{listing}{Definition des Zyklenstempels}
\end{code}

Die statische Variable speichert die Ausgangszyklenzahl und dient als
Referenzpunkt zur Normalisierung der Messwerte.

\subsubsection{Beim Kontextwechsel}

FreeRTOS bietet Makros, die beim Kontextwechsel, oder genauer gesagt zu Beginn
und beim Abschluss jedes Zeitabschnitts (engl. Time Slice) einer laufenden Task,
als ISR-Callbacks aufgerufen werden können.(\ref{sec:trace_hooks}). Das Makro
\mintinline{cpp}|traceTASK_SWITCHED_IN()| wird aufgerufen, nachdem eine Task zum
Ausführen oder Fortfahren ausgewählt wurde.
\mintinline{cpp}|traceTASK_SWITCHED_OUT()| wird aufgerufen, unmittelbar bevor
der Programmlauf zu einer neuen Task gewechselt wird. An diesen Zeitpunkten
innerhalb vom Scheduling-Code enthält \mintinline{cpp}|pxCurrentTCB| (der
interne Task-Control-Block-Struktur von FreeRTOS) die Metadaten der aktuellen
Task, wodurch der Nutzer die Möglichkeit hat, direkt darauf als
Funktionsargument zuzugreifen, um Informationen über die gerade laufenden Task
zu erlangen. (\cite{freertos_rtos_trace_hooks})

Da die Definitionen solcher Makros immer vor der Einbindung der
\mintinline{text}|FreeRTOS.h| erfolgen müssen, können sie einfachheitshalber
am Ende der \mintinline{text}|FreeRTOSConfig.h| definiert werden.

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin);
#define traceTASK_SWITCHED_IN() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 1)
#define traceTASK_SWITCHED_OUT() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 0)
\end{minted}
    \captionof{listing}{Konkrete Definition der Trace Hook Makros}
\end{code}

Hierbei werden die Makros jeweils als ein Aufruf der Funktion
\mintinline{cpp}|task_switched_isr()| mit dem Namen der aktuellen Task
\mintinline{cpp}|pcTaskName| sowie einen boolesche Start/End-Marker, definiert
als \mintinline{cpp}|uint8_t| um das Einbinden von \mintinline{cpp}|<stdbool.h>|
zu sparen, definiert.

Das Feld \mintinline{cpp}|uxTaskNumber| vom Typ \mintinline{cpp}|unsigned long|
aus dem \mintinline{cpp}|pxCurrentTCB|-Objekt, das eigentlich speziell zur
Task-Identifizierung für Drittanbieter-Softwares konzipiert
ist~\cite{freertos_task_c_410}, kann in dem Falle auch als möglicherweise der
leichtgewichtigste Identifikator genutzt werden. Da das Ausgeben des
menschenlesbaren Namens keinen Bottleneck bei der IO-Übertragung verursacht und
man in der Nachbearbeitung nicht mehr manuell jeden generierten Zyklenstempel
der zugehörigen Task beziehungsweise deren Funktionsname zuordnen muss, wird
hier einfachheitshalber auf den Namen entschieden.

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin) {
  if (!stamping_enabled) return;
  stamp(name, is_begin);
  ctx_switch_cnt += 1;
}

void stamp(const char* name, bool is_begin) {
  volatile auto cycle = DWT->CYCCNT;
  volatile auto idx = stamp_idx.fetch_add(1);
  stamps[idx % STAMP_BUF_SIZE] = {name, cycle, is_begin};
}
\end{minted}
    \captionof{listing}{Zyklenstempelgenerierung beim Kontextwechsel}
\end{code}

Die Funktion überprüft zunächst, ob die Aufzeichnung beim Kontextwechsel
durchgeführt werden soll, und ruft anschließend \mintinline{cpp}|stamp()| auf,
wenn dies der Fall ist. Nebenbei wird ein Zähler inkrementiert, der die
akkumulierte Anzahl von Kontextwechsel repräsentiert.

Da das Schreiben eines Zyklenstempel bestehend aus mehreren Bytes in die Senke
gleichzeitig aus mehreren Threads per se nicht „lock-free“ sein kann, darf es
nicht direkt in einer ISR durchgeführt werden. Stattdessen müssen die Daten
zuerst in einen temporären Puffer reingeschrieben werden.

\begin{code}
\begin{minted}{cpp}
inline constexpr size_t ISR_STAMP_BUF_SIZE = 512;

inline std::array<cycle_stamp, STAMP_BUF_SIZE> isr_stamps{};
volatile inline size_t isr_stamp_idx = 0;
volatile inline bool stamping_enabled = 0;
\end{minted}
    \captionof{listing}{Temporärpuffer mit dessen atomaren Schreibzeiger und
    Aktivierungsflag}
\end{code}

Die erfassten ISR-Zykluszahlen werden zusätzlich von einer kleinen FreeRTOS-Task
in einen menschenlesbaren String umgewandelt und in die Senke geschrieben.

\begin{code}
    \begin{minted}{cpp}
static size_t prev_idx = 0;
auto output_stamps = []() static {
  auto end = stamp_idx;
  // auto diff = end - prev_idx;
  while (prev_idx != end) {
    const auto& [name, cycle, is_begin] =
        stamps[normalized_index(prev_idx++)];
    write_blocking(
        buf,
        snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                 cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
  }
};
    \end{minted}
    \captionof{listing}{Callback zur Ausgabe von ISR-Zyklenstempeln}
\end{code}

\subsubsection{Im Nicht-ISR-Kontext}

Für Nicht-ISR-Kontexte ist die Funktion zur direkten Ausgabe eines
Zyklusstempels wie folgt definiert:

\begin{code}
\begin{minted}{cpp}
inline void stamp_direct(const char* name, bool is_begin) {
  volatile auto cycle = DWT->CYCCNT;
  char buf[50];
  tsink::write_blocking(
      buf, snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                    cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
  ;
}

struct cycle_stamp_raii {
  cycle_stamp_raii(const char* name) : name{name} {
    if (stamping_enabled) stamp_direct(name, true);
  }
  ~cycle_stamp_raii() {
    if (stamping_enabled) stamp_direct(name, false);
  }

  const char* name;
};
\end{minted}
    \captionof{listing}{Funktion zur Ausgabe von Zyklenstempeln}
\end{code}

Das RAII-Konzept kommt ebenfalls hier zur Anwendung: Beim Erstellen eines
Objekts dieses Typs wird automatisch \mintinline{cpp}|stamp_direct()|
aufgerufen, beim Zerstören (beim Verlassen des Gültigkeitsbereichs) erneut.
Dadurch markiert es Beginn und Ende eines zeitkritischen Abschnitts und
ermittelt dessen Dauer.

\begin{code}
\begin{minted}{cpp}
void func()
{ // --> t1 stamp in
  cycle_stamp_raii t1{"func"};
  { // --> t2 stamp in
    cycle_stamp_raii t2{"code block"};
  } // --> t2 stamp out
} // --> t1 stamp out
\end{minted}
    \captionof{listing}{Beispielnutzung des RAII-Strukturtyps}
\end{code}

Unmittelbar nach der Erstellung eines solchen RAII-Objekts sollte eine
Memory-Barrier-Anweisung erfolgen. Damit wird sichergestellt, dass das Objekt
tatsächlich zum definierten Zeitpunkt erstellt wird und nicht durch
Optimierungen oder die CPU-Pipeline neu angeordnet wird.
\mintinline{cpp}|std::memory_order_seq_cst| wirkt als vollständige
Memory-Barrier-Anweisung~\cite{cppreference_memory_order} und entspricht
\mintinline{cpp}|__sync_synchronize()| aus der C-Welt.

\begin{code}
\begin{minted}{cpp}
freertos::cycle_stamp_raii _{"p_ctrl"};
std::atomic_thread_fence(std::memory_order_seq_cst);
\end{minted}
    \captionof{listing}{Generierung eines Zyklenstempels via eines RAII-Objekts}
\end{code}

Laut des ISO-C++-Standards aus dem Jahr 2020 wird der Aufruf von Destruktoren
mit „Side Effects”\footnotemark{} nicht durch Optimierung eliminiert und erfolgt
garantiert am Ende des Ausführungsblocks, selbst wenn das Objekt nicht genutzt
zu sein scheint~\cite[§6.7.5.4 Abs. 3]{iso_iec_14882_2020}, und zwar in der
umgekehrten Reihenfolge, wie die Objekte kreiert worden sind
\cite{isocpp_dtor_order}.

\footnotetext{Zu „Side Effects” zählen unter anderem Schreibzugriffe von
Objekten sowie Schreib- und Lesezugriffe auf ein
\mintinline{cpp}|volatile|-Objekt.~\cite{cppreference_eval_order}}

% Mit einem kritischen Abschnitt kann somit sichergestellt werden, dass zwischen
% der Lesezugriff auf den Schreibindex \mintinline{cpp}|stamp_idx| und dessen
% Inkrementierung nicht durch Kontextwechsel unterbrochen wird, so dass die
% geschriebene Daten nicht unmittelbar vor der Inkrementierung des Schreibindexes
% von anderen Threads überschrieben werden.

% Mittels einer booleschen Variable als Template-Argument, kombiniert mit
% \mintinline{cpp}|if constexpr|, kann zur Übersetzungszeit festgelegt werden, ob
% das Objekt erzeugt oder weggelassen werden soll. Konkret werden dabei zwei
% unterschiedliche Versionen dieser Funktion durch den Compiler generiert, wodurch
% das Branching zur Laufzeit vollständig eliminiert wird
% \cite{cppreference_constexpr_if}. Je nachdem, ob der Boolean falsch oder wahr
% ist, wird die entsprechende Version mit oder ohne die Erzeugung des Objekts für
% den kritischen Abschnitt aufgerufen.

\subsection{Streaming-Mode via Button}

Laut Benutzerhandbuch des Boards ist der User-Button standardmäßig mit dem
I/O-Pin PC13 verbunden~\cite[S. 24, 6.6]{stm32_nucleo144_user_manual}, was der
EXTI-Linie 13 entspricht~\cite[S. 322, 11.8]{stm32f7_ref_manual}.
Praktischerweise muss in STM32CubeMX nur die Option für EXTI-Line-Interrupts der
Linien 10 bis 15 unter \textit{System Core/NVIC} aktiviert werden, sodass der
Button bei jedem Druck einen Interrupt auslöst.

Im entsprechenden Interrupt-Callback wird ein Toggle-Mechanismus implementiert:
Bei jedem Auslösen wird die boolesche Variable
\mintinline{cpp}|stamping_enabled| invertiert. Gleichzeitig wird die
Profiling-Task benachrichtigt, um die ISR-Zyklenstempel auszugeben.


\begin{code}
\begin{minted}{cpp}
void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) {
  static constexpr uint8_t DEBOUNCE_TIME_MS = 50;
  static volatile uint32_t last_interrupt_time = 0;

  if (GPIO_Pin != USER_Btn_Pin) return;

  uint32_t current_time = HAL_GetTick();
  if (current_time - std::exchange(last_interrupt_time, current_time) >
      DEBOUNCE_TIME_MS) {
    stamping_enabled ^= 1;
    if (stamping_enabled) {
      stamp_idx = 0;
      cycle_stamp::initial_cycle = DWT->CYCCNT;

      static BaseType_t xHigherPriorityTaskWoken;
      vTaskNotifyGiveFromISR(profiling_task_hdl, &xHigherPriorityTaskWoken);
      portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
    }
  }
}
\end{minted}
    \captionof{listing}{Interrupt-Callback für den User-Button}
\end{code}

Um ungewollte Mehrfachauslösungen durch unpräzises Drücken zu vermeiden, ist
eine kurze Debounce-Zeit notwendig.

Zusammenfassend lässt sich festhalten, dass sich mithilfe von
FreeRTOS-Trace-Hooks und RAII-basierter Zyklenstempelerfassung – kombiniert mit
dem vorhandenen User-Button – ein leichtgewichtiges Profiling-System für
FreeRTOS-Tasks und zeitkritische Codeabschnitte realisieren lässt.

\subsection{Visualisierung von Profiling-Daten}

% FIXME: alignment
Die Profiling-Daten werden im menschenlesbaren Format
\mintinline{text}|<Identifikator> <konvertierte Zeit> <Start-/End-Marker>|
umgerechnet in Mikrosekunden ausgegeben.

\begin{code}
\begin{minted}{cpp}
IDLE 1 0        << mittels FreeRTOS-Task periodisch ausgegeben
profile 2 1     << mittels FreeRTOS-Task periodisch ausgegeben
w_ctrl 7413 1   << in Echtzeit ausgegeben
w_ctrl 7504 0   << in Echtzeit ausgegeben
odom 7951 1     << in Echtzeit ausgegeben
odom 7969 0     << in Echtzeit ausgegeben
profile 28 0    << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 29 1       << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 332 0      << mittels FreeRTOS-Task periodisch ausgegeben
tsink 333 1     << mittels FreeRTOS-Task periodisch ausgegeben
tsink 336 0     << mittels FreeRTOS-Task periodisch ausgegeben
...
\end{minted}
    \captionof{listing}{Ausschnitt der Profiling-Daten}
\end{code}

Sie folgen nicht einer strikt aufsteigenden Reihenfolge nach den konvertierten
Zeiten, da die von den ISR generierten Zyklenstempel zunächst
zwischengespeichert und erst später durch eine FreeRTOS-Task in einer frei
wählbaren Frequenz ausgegeben werden müssen. Da jedoch jeder Zyklenstempel in
Echtzeit ohne Verzögerung oder Overhead erzeugt wird, spiegelt die entsprechende
Zyklenzahl und somit die konvertierten Zeitpunkten in Mikrosekunden die
tatsächlichen Echtzeitaspekte des Systems korrekt wider. Daher ist eine strikt
geordnete Ausgabe nicht zwingend erforderlich.

Es wurde versucht, die parallele Ausgabe zu synchronisieren: Jeder Thread ruft
die Schreibfunktion mit einem atomar inkrementierten Zähler auf. Dieser wird
dann mit dem internen Zähler verglichen. Stimmen die Werte überein, wird die
Schreiboperation ausgeführt, andernfalls wird der Thread blockiert. Dieser
Versuch erwies sich als nicht erfolgreich, da die resultierende Performance
aufgrund des nicht-deterministischen Schedulings um die Hälfte sank.

Anschließend wurde versucht, alle Zyklenstempel zunächst in dem statischen
Puffer zwischenzuspeichern, um das Erzeugen und Ausgabe komplett voneinander zu
trennen. Mit diesem Ansatz konnte die Reihenfolge konsistent gehalten werden.

\begin{code}
\begin{minted}{cpp}
uros 2 0
profile 2 1
profile 28 0
...
w_ctrl 14031 1
w_ctrl 14133 0
\end{minted}
    \captionof{listing}{Profiling-Daten in aufsteigender Reihenfolge}
\end{code}
