\section{Umsetzung}

Nachdem die Steuerungssoftware sowohl für FreeRTOS als auch für Micro-ROS
entwickelt wurde, wird nun eine Methode zur Erfassung von Laufzeitdaten
entwickelt. Sie basiert auf FreeRTOS, um später die Portierung auf Micro-ROS
nahtlos zu ermöglichen. Ziel dabei ist es, die Ausführungszeiten von Tasks und
zeitkritischen Funktionen mittels DWT (\ref{sec:dwt}) präzise zu erfassen.

Der Ansatz besteht grundsätzlich darin, zu Beginn und am Ende jedes
Messabschnitts die aktuelle Zyklenzahl zu speichern.

Aufgrund von Hardwareeinschränkungen und aus Gründen der Einfachheit wurde UART
als Schnittstelle zur Datenübertragung zwischen Mikrocontroller und Host
gewählt. Mit einer theoretischen Übertragungsrate von bis zu
$12,5\,\text{Mbit/s}$ bietet UART genügend Bandbreite~\cite[S.
2]{stm32_datasheet}, um die erfassten Daten zur Laufzeit kontinuierlich zu
übertragen.

Aus den inhärenten Eigenschaften der Multithreaded-Software ergibt sich zunächst
die Notwendigkeit, eine threadsichere \ac{MPSC}-Queue zu implementieren. Diese
dient als eine Multi-Producer-Senke für die erfassten Laufzeitdaten und leitet
sie zur Verarbeitung über UART weiter. Die vorhandenen Stream- oder
Messagebuffer von FreeRTOS eignen sich nicht für mehrere
Producer~\cite{FreeRTOSStreamBuffer}, und können in dem Fall nicht verwendet
werden.

\subsection{Multi-Producer-Senke}

Die grundlegende Idee sieht vor, dass Daten aus mehreren Tasks bzw. Threads
direkt in die Senke -- genauer gesagt in einen internen, statischen Ringpuffer
-- geschrieben werden. Die Speicherung in einem statischen Puffer ist wesentlich
schneller als beispielsweise die Verwendung einer verketteten Liste, da diese
unter anderem dynamische Heap-Allokationen erfordern würde und zudem auch nicht
cache-optimal ist.

Da der vorab allokierte Speicher zwangsläufig begrenzt ist, muss die Senke im
schlimmsten Fall erkennen können, wann sie weitere Schreibzugriffe blockieren
muss. So wird verhindert, dass noch nicht verarbeitete Daten überschrieben
werden.

Durch die Kombination von DMA mit Interrupts, die bei Abschluss jeder
DMA-Übertragung ausgelöst werden, lässt sich dabei die I/O-gebundene Wartezeit
eliminieren. In diesem Fall reduziert sich die Ausgabe von Laufzeitdaten auf das
reine Schreiben in den Ringpuffer, während die eigentliche I/O-Operation durch
den DMA-Controller unabhängig vom Prozessor erfolgt. Vorausgesetzt die I/O
überträgt die Daten schnell genug, um mit dem Eingangsdatenstrom Schritt zu
halten, entstehen keine Blockaden, in denen Tasks oder Threads auf freien
Speicherplatz warten müssen.

Daher wird der Ansatz mit DMA fortgeführt, da in diesem Fall die Datenausgabe
idealerweise nur wenige Taktzyklen ohne Wartezeit benötigt und sich aus Sicht
des Prozessors bzw. Threads nahezu als nicht-blockierende Operation verhält.

\subsubsection{Aufbau}

Die Senke besteht im Wesentlichen aus einem statisch allokierten Ringpuffer
gepaart mit einem Schreib- und Lesezeiger. Diese Zeiger bzw. Indizes ermöglichen
es unter anderem, die Größe der geschriebenen Daten sowie den verbleibenden
Speicherplatz zu ermitteln.

In der ersten Implementierungsversion wird die Menge der geschriebenen Daten als
Differenz zwischen dem Schreib- und Leseindex berechnet, wenn der Schreibindex
numerisch \textit{nach} dem Leseindex liegt. Andernfalls umfassen die
geschriebenen Daten die Reihe vom Leseindex bis zum Pufferende sowie vom
Pufferanfang bis zum Schreibindex, da die beiden Indizes stets korrekt im
Ringpuffer positioniert sind.

Hierbei muss zusätzlich der Sonderfall berücksichtigt werden, bei dem beide
Indizes auf dieselbe Position zeigen: Entweder ist der Ringpuffer leer oder
vollständig gefüllt. Das Problem lässt sich dadurch lösen, indem der Schreiber
überprüft, ob das Byte an der aktuellen Position noch unverarbeitet ist, oder
wurde es bereits gelesen und kann somit überschrieben werden. Bei dem Sonderfall
impliziert dies: wenn das aktuelle Byte nicht mehr überschreibbar ist, dann ist
die Senke voll beschrieben.

In einem C++-Konferenzvortrag über eine
\ac{MPMC}-Queue~\cite{CppCon2024LockFreeQueue} basiert deren Implementierung auf
folgendem Prinzip: Jede Position des Datenpuffers besitzt eine eindeutige
Schreibsequenznummer. Bei jedem Lesevorgang wird diese atomar um die Gesamtlänge
$N$ des Puffers erhöht. Dadurch wird signalisiert, dass die Daten in dieser
Position in Iteration $N$ verarbeitet wurden und in Iteration $N+1$ vom
Schreiber überschrieben werden können. Die Entscheidung hierüber erfolgt durch
Vergleich mit einer globalen Schreibsequenznummer, die ebenfalls nach jedem
Schreibvorgang atomar inkrementiert wird.

Für den Fall einer Senke mit einem einzigen Consumer genügt es, den Zustand als
\mintinline{cpp}|bool| zu speichern. Dieser gibt an, ob die Daten an einer
bestimmten Position noch verarbeitet werden müssen oder bereits überschrieben
werden können.

Um die Fallunterscheidungen mit den Schreib- und Leseindizes sowie den
zusätzlichen Speicherbedarf zur Zustandsspeicherung in der finalen
Implementierung zu eliminieren, können die Indizes auf eine stets korrekte
Positionierung verzichten. Stattdessen können sie einfach über den Puffer hinaus
zählen. Bei jeder Verwendung wird ihr Wert durch eine Modulo-Operation mit der
Puffergröße normalisiert, wodurch sie dann auf die korrekte Position verweisen.
Demnach reduziert sich die Berechnung der verfügbaren Datenmenge ebenfalls auf
eine einfache Subtraktion zwischen beiden Indizes (\ref{code:sink_structure}) --
vorausgesetzt, dass beide Indizes vorzeichenlos sind.

Wenn die Puffergröße eine Zweierpotenz ist, kann die Modulo-Operation hier
ebenfalls auf eine Ein-Zyklus-UND-Verknüpfung reduziert werden
\cite{stackoverflow_mod, arm_instruction_set}.

\begin{code}
\begin{minted}{cpp}
#ifndef TSINK_CAPACITY
constexpr size_t TSINK_CAPACITY = 2048;
#endif
uint8_t sink[TSINK_CAPACITY]{};
volatile size_t read_idx = 0;
std::atomic<size_t> write_idx = 0;

size_t size() { return write_idx - read_idx; }
size_t space() { return TSINK_CAPACITY - size(); }
size_t normalize(size_t idx) { return idx % TSINK_CAPACITY; }
\end{minted}
    \captionof{listing}{Struktur der Senke}
    \label{code:sink_structure}
\end{code}

\subsubsection{Schreibvorgang}

Auf der ARM-Architektur sind Zugriffe auf Bytes, Halbdatenworte (16-Bit) sowie
Datenworte (32-Bit) standardmäßig atomar, sofern sie im Speicher ausgerichtet
sind~\cite[S. A3-79]{ARM_DDI0403_EE} und verursachen somit keine
Schreib-Lese-Konflikte.

Es muss aber sichergestellt werden, dass bei Multithreaded-Zugriffen nur ein
Thread die nächste freie Position des Ringpuffers beschreibt.

Hier lässt sich eine \ac{CAS}-Operation (\ref{code:cas}) nutzen, um
sicherzustellen, dass der Schreibindex bei konkurrierendem Zugriff durch den
atomaren Vergleich mit einem übergebenen Wert nur von einem Thread inkrementiert
wird. Nach erfolgreicher Inkrementierung darf dann der Thread Daten an der
beanspruchten Indexposition beschreiben.

\begin{code}
\begin{minted}{cpp}
bool write_or_fail(uint8_t elem) {
  auto expected = write_idx.load();
  if (expected - read_idx == TSINK_CAPACITY) return false;
  if (write_idx.compare_exchange_strong(expected, expected + 1)) {
    sink[normalize(expected)] = elem;
    return true;
  }
  return false;
}
\end{minted}
    \captionof{listing}{atomare Schreiboperation in der Senke}
    \label{code:cas}
\end{code}

Zunächst wird der aktuelle Schreibindex als lokale Variable
\mintinline{cpp}|expected| zwischengespeichert. Dann wird geprüft, ob der Puffer
mit diesem Schreibindex bereits voll ist -- in diesem Fall erfolgt eine
vorzeitige Rückkehr. Andernfalls ist diese Position frei und beschreibbar. Diese
Garantie gilt ab diesem Zeitpunkt und bleibt auch in Zukunft bestehen, da die
Senke danach nur noch weiteren Speicherplatz freigeben kann.

Anschließend wird die CAS-Operation durchgeführt, bei der der Schreibindex mit
dem zwischengespeicherten Wert verglichen und nur bei Übereinstimmung
inkrementiert wird.

Der zwischengespeicherte Wert erfüllt somit eine Doppelfunktion: Er dient sowohl
zur Speicherplatzprüfung, als auch als Synchronisationstoken für die
Indexinkkrementierung. Falls der Schreibindex bereits inkrementiert wurde,
scheitert der atomare Vergleich, sodass die CAS-Operation
\mintinline{cpp}|false| zurückgibt und der Schreibvorgang abgebrochen wird.

Durch die Ausführung dieser kombinierten atomaren Operation (Vergleich und
Inkrementierung) mit Statusrückmeldung wird sichergestellt, dass letztlich nur
ein Thread den Schreibindex erfolgreich inkrementieren und folglich Daten
schreiben kann. Diese CAS-basierte Synchronisation mit anderen Threads erfolgt
daher nicht-blockierend im Vergleich zur einfachen Deaktivierung von Interrupts.

Um das Schreiben mehrerer Bytes ebenfalls threadsicher zu gestalten, muss der
gesamte Schreibvorgang (\ref{code:write_op}) durch geeignete
Synchronisationsmechanismen geschützt werden~\cite{FreeRTOSForumPrintf}. Hier
wird ein Mutex verwendet, da dieser im Gegensatz zu einem Semaphor sicherstellt,
dass der Thread den Mutex und damit die Kontrolle umgehend freigibt und nicht
aufgrund niedrigerer Priorität blockiert wird (\ref{sec:mutex}).

\begin{code}
\begin{minted}{cpp}
struct mtx_guard {
  mtx_guard() { configASSERT(xSemaphoreTake(write_mtx, portMAX_DELAY)); }
  ~mtx_guard() { configASSERT(xSemaphoreGive(write_mtx)); }
};

void write_blocking(const uint8_t* ptr, size_t len) {
  while (true) {
    if (volatile auto _ = mtx_guard{}; space() >= len) {
      for (size_t i = 0; i < len; ++i) configASSERT(write_or_fail(ptr[i]));
      return;
    }
    vTaskDelay(pdMS_TO_TICKS(1));
  }
}
\end{minted}
    \captionof{listing}{Blockierende Schreiboperation in die Senke}
    \label{code:write_op}
\end{code}

Der Mutex-Wrapper \mintinline{cpp}|struct mtx_guard| nutzt \ac{RAII}, um beim
Erstellen eines Objekts automatisch den Mutex zu sperren und ihn beim Verlassen
des Gültigkeitsbereichs -- in diesem Fall beim Verlassen des
\mintinline{cpp}|if|-Blocks -- wieder freizugeben. Falls nicht genügend Platz in
der Senke vorhanden ist, wird kooperativ der Kontrollfluss für eine Millisekunde
an den Scheduler zurückgegeben, um andauerndes Polling zu vermeiden.

\subsubsection{Lesevorgang}

Eine statisch allokierte FreeRTOS-Task (\ref{code:consumer_task}) wird erzeugt,
die kontinuierlich versucht, verfügbare Daten aus der Senke zu verarbeiten.

\begin{code}
\begin{minted}{cpp}
using consume_fn = void (*)(const uint8_t*, size_t);
consume_fn consume;

void task_impl(void*) {
  auto consume_and_wait = [](size_t pos, size_t size) static {
    if (!size) return;
    consume(sink + pos, size);
    ulTaskNotifyTake(pdFALSE, portMAX_DELAY);
  };

  while (true) {
    if (size_t sz = size(); sz) {
      auto idx = normalize(read_idx);
      auto wrap_around = ((idx + sz) / TSINK_CAPACITY) *  // multiplier as bool
                         ((idx + sz) % TSINK_CAPACITY);   // actual amount
      auto immediate = sz - wrap_around;
      consume_and_wait(idx, immediate);
      consume_and_wait(0, wrap_around);
      read_idx += sz;
    } else {
      vTaskDelay(pdMS_TO_TICKS(1));
    }
  }
}
\end{minted}
    \captionof{listing}{Implementierung der Task zur Datenverarbeitung}
    \label{code:consumer_task}
\end{code}

Zunächst wird der mögliche Anteil der verfügbaren Daten, der sich vom
Pufferanfang bis zum Schreibindex erstreckt, mathematisch berechnet. Dieser
Anteil existiert und wird nur gültig sein, wenn nach der Normalisierung der
beiden Indizes der Schreibindex \textit{hinter} dem Leseindex liegt: In diesem
Fall wurde der Ringpuffer bereits bis zum Ende beschrieben und beginnt wieder am
Anfang. Dann wird die (Teil-)Menge vom aktuellen Leseindex bis zum Schreibindex
oder Pufferende -- abhängig von dem zuvor berechneten Anteil -- bestimmt. Diese
Vorgehensweise ist notwendig, da die API zur UART-Übertragung nur einen Zeiger
zu einem Datenpuffer und eine Größe als Parameter erwartet und der Ringpuffer
aufgrund seiner Funktionsweise dies berücksichtigen muss.

Bei jedem Aufruf von \mintinline{cpp}|consume_and_wait()| wird durch die
blockierende API zur Task-Notification (\mintinline{cpp}|ulTaskNotifyTake()|
\ref{sec:direct_task_notification}) auf den Abschluss der aktuell laufenden
I/O-Übertragung gewartet, bevor eine neue gestartet werden kann. Diese
Vorgehensweise ist ebenfalls notwendig bei Übertragungen mittels DMA: Die
zugehörige Übertragungsfunktion aus der STM32-HAL signalisiert dabei lediglich
der Hardware den gewünschten Transfervorgang und kehrt sofort
zurück~\cite{HAL_UART_Transmit_DMA}, sodass der Programmfluss unmittelbar
fortgesetzt wird. Zudem ist das globale, intern genutzte UART-Zustandsobjekt
auch nicht wiedereintrittsfähig\footnote{„Als wiedereintrittsfähig -- zu
englisch reentrant -- wird ein Programm-Attribut beschrieben, welches die
mehrfache (quasi-gleichzeitige) Nutzung eines Programm-Codes erlaubt, sodass
sich gleichzeitig (oder quasi-gleichzeitig) ausgeführte Instanzen nicht
gegenseitig
beeinflussen.”~\cite{wiedereintrittsfaehigkeit}}~\cite{stm32_hal_reentrancy},
weshalb die zugehörigen APIs nicht aus mehreren Threads gleichzeitig aufgerufen
werden dürfen. Daher müssen nachfolgende Aufrufe hierbei miteinander
synchronisiert werden.

Analog zu \ref{code:uart_isr} wird die Task erst wieder entblockt, wenn eine
Task-Notification durch den Aufruf der Callback-Funktion \ref{code:task_noti_cb}
eintrifft.

\begin{code}
\begin{minted}{cpp}
enum struct CALL_FROM { ISR, NON_ISR };

template <CALL_FROM callsite>
void consume_complete() {
  if constexpr (callsite == CALL_FROM::ISR) {
    static BaseType_t xHigherPriorityTaskWoken;
    vTaskNotifyGiveFromISR(task_hdl, &xHigherPriorityTaskWoken);
    portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
  } else {
    xTaskNotifyGive(task_hdl);
  }
}
\end{minted}
    \captionof{listing}{Callback-Funktion für die Task-Notification}
    \label{code:task_noti_cb}
\end{code}

Für die Nutzung dieser Senke mit UART-DMA und aktiviertem Datencache muss somit
zunächst eine ISR \ref{code:dma_irq_cb} definiert werden, das nach jeder
DMA-Übertragung ausgelöst wird und die Callback-Funktion
(\ref{code:task_noti_cb}) aufruft.

\begin{code}
\begin{minted}{cpp}
void HAL_UART_TxCpltCallback(UART_HandleTypeDef* huart) {
  if (huart->Instance == huart3.Instance)
    tsink::consume_complete<tsink::CALL_FROM::ISR>();
}
\end{minted}
    \captionof{listing}{Interrupt-Callback bei Abschluss einer UART-Übertragung}
    \label{code:dma_irq_cb}
\end{code}

Die Senke wird durch den Aufruf ihrer Initialisierungsfunktion
(\ref{code:sink_initialization}) bereitgestellt. Diese erwartet einen
Funktionszeiger, dessen Implementierung eine cache-kohärente Datenverarbeitung
(\ref{code:cache_clean}) durchführt, sowie eine Priorität für die interne Task
(\ref{code:consumer_task}) als Funktionsargumente.

\begin{code}
\begin{minted}{cpp}
void main() {
  auto tsink_consume_dma = [](const uint8_t* buf, size_t size) static {
    auto flush_cache_aligned = [](uintptr_t addr, size_t size) static {
      constexpr auto align_addr = [](uintptr_t addr) { return addr & ~0x1F; };
      constexpr auto align_size = [](uintptr_t addr, size_t size) {
        return size + ((addr) & 0x1F);
      };

      SCB_CleanDCache_by_Addr(reinterpret_cast<uint32_t*>(align_addr(addr)),
                              align_size(addr, size));
    };

    flush_cache_aligned(reinterpret_cast<uintptr_t>(buf), size);
    HAL_UART_Transmit_DMA(&huart3, buf, size);
  };
  tsink::init(tsink_consume_dma, osPriorityAboveNormal);
}
\end{minted}
    \captionof{listing}{Initialisierung der Senke mit DMA}
    \label{code:sink_initialization}
\end{code}

% \subsubsection{Nutzung der Senke mit blockierender I/O}
%
% Ähnlich wie bei der Initialisierung über DMA, entfällt hier aber das
% Interrupt-Callback, und die Funktion zur Datenverarbeitung wird durch die
% Verwendung einer blockierenden Übertragungsfunktion ohne Leerung von Cache
% vereinfacht, da ohne DMA keine manuelle Sicherstellung der Cache-Kohärenz
% notwendig ist.
%
% \begin{code}
% \begin{minted}{cpp}
% int main() {
%   auto tsink_consume = [](const uint8_t* buf, size_t size) static {
%     HAL_UART_Transmit(&huart3, buf, size, HAL_MAX_DELAY);
%     tsink::consume_complete<tsink::CALL_FROM::NON_ISR>();
%   };
%
%   tsink::init(tsink_consume, osPriorityAboveNormal);
% }
% \end{minted}
%     \captionof{listing}{Initialisierung der Senke mit blockierender I/O}
% \end{code}
%
% Vielleicht wäre es sinnvoll, die beiden Befehle in einen kritischen Abschnitt zu
% packen, um Kontextwechsel zwischen ihnen zu verhindern und damit Verzögerungen
% bei der Signalisierung an die Senke zu vermeiden. Da die Senke im Rahmen dieser
% Arbeit ausschließlich mit DMA genutzt wird, wird dieses Beispiel nicht weiter
% berücksichtigt.

% \subsubsection{Benchmark}
%
% Ein Benchmark für die Senke wurde entwickelt, um deren Leistung unter paralleler
% Last zu testen. Der Benchmark lässt eine Anzahl von
% \mintinline{text}|BENCHMARK_N = 5| Threads gleichzeitig laufen, die jeweils eine
% Anzahl von \mintinline{cpp}|iteration = 5000| Nachrichten mit ca. 80 Charaktern
% nach Formatierung hintereinander über die Senke ausgeben.
%
% Nach Abschluss des Benchmarks werden die gemessenen Zeiten und die
% Laufzeitstatistiken der jeweiligen Task ausgegeben.
%
% \begin{minipage}[t]{0.5\textwidth}
%     \begin{code}
%         \begin{minted}[linenos=false]{cpp}
% time in ms: 7576
% time in ms: 8071
% time in ms: 9064
% time in ms: 9386
% time in ms: 9571
% ===================================
% Task            Time            %%
% print_bench     0               <1%
% IDLE            72844           76%
% benchmark       4385            4%
% benchmark       4221            4%
% benchmark       4374            4%
% benchmark       4470            4%
% benchmark       4169            4%
% tsink           312             <1%
% Tmr Svc         0               <1%
%     \end{minted}
%         \captionof{listing}{Benchmark mit DMA}
%     \end{code}
% \end{minipage}
% \hfill
% \begin{minipage}[t]{0.5\textwidth}
%     \begin{code}
%         \begin{minted}[linenos=false]{cpp}
% time in ms: 10964
% time in ms: 11016
% time in ms: 11285
% time in ms: 11379
% time in ms: 11405
% ===================================
% Task            Time            %%
% print_bench     0               <1%
% IDLE            0               <1%
% benchmark       3624            3%
% benchmark       3637            3%
% benchmark       3623            3%
% benchmark       3644            3%
% benchmark       3631            3%
% tsink           94876           83%
% Tmr Svc         0               <1%
%     \end{minted}
%         \captionof{listing}{Benchmark mit blockierender I/O}
%     \end{code}
% \end{minipage}
%
% Die Ausgabe enthält zwei verschiedene Zeitmessungen für den Benchmark. Die erste
% Messung erfasst die Zeitspanne vom Start der jeweiligen Task bis zu dessen
% Beendigung. Die zweite Messung bezieht sich auf die
% FreeRTOS-Laufzeitstatistiken, die durch \mintinline{cpp}|vTaskGetRunTimeStats()|
% formatiert ausgegeben sind. Diese liefern die absolute, akkumulierte Zeit für
% jede Task, die im Zustand „Running” verbracht hat, sowie deren prozentualen
% Anteil an der Gesamtlaufzeit \cite{freertos_runtime_stats}.
%
% Der Benchmark zeigt, dass asynchrone Übertragung per DMA die Gesamtlaufzeit des
% Benchmark-Prozesses im Vergleich zur I/O-gebundenen Variante um etwa $16\,\%$
% verringerte, während gleichzeitig die I/O-gebundene Zeit freigegeben wurde,
% sodass sie von anderen Tasks genutzt werden kann.
%
% Ebenso kann abgeleitet werden, dass durch die Verwendung von DMA die
% Datenübertragungsrate nahezu das vorkonfigurierte Maximum der Baudrate von
% $2.000.000\,\text{bps}$ erreicht wurde: Insgesamt wurden $1.908.759$ Bytes
% übertragen, dabei hat ein UART-Frame per Byte eine standardmäßige Wortlänge von
% 8 Bit, inklusive je 1 Start- und 1 Stopp-Bit, ohne Paritätsbit.
%
% \begin{align*}
%     1.908.355\text{\,B} \times 10\text{\,b per Frame} =
%     19.083.550 \text{\,b} = \text{Gesamte Bits}
% \end{align*}
%
% Teilt man dies durch die gesamte Übertragungszeit, ergibt sich die effektive
% Bitrate sowie der prozentuale Anteil im Vergleich zur maximalen Baudrate:
%
% \begin{align*}
%     \text{Bitrate bei DMA} =
%     \frac{19.083.550\text{\,b}}{9,571\text{\,s}} \approx
%     1.993.893,01 \text{\,bps} \\
%     \quad \Rightarrow 99,70\,\%\text{ des Maximums} \\
%     \\
%     \text{Bitrate bei blockierender I/O} =
%     \frac{19.083.550\text{\,b}}{11,405\text{\,s}} \approx
%     1.673.261,73 \text{\,bps} \\
%     \quad \Rightarrow 83,66\,\% \text{ des Maximums}
% \end{align*}
%
% Der Code für die Senke sowie den Benchmark befinden sich in den
% Repositorys~\cite{freertos_threadsafe_sink, freertos_tsink_benchmark}.

\subsection{Aufzeichnung von Zyklenstempeln}

Wie im vorherigen Abschnitt \ref{sec:dwt} erläutert, eignet sich die DWT zur
Generierung von Laufzeitdaten in Form von Zyklenzahlen. Mit den folgenden
Konfigurationsschritten (\ref{code:dwt_activate_conf}) kann sie aktiviert
werden:

\begin{code}
\begin{minted}{cpp}
void enable_dwt() {
  CoreDebug->DEMCR |= CoreDebug_DEMCR_TRCENA_Msk;
  DWT->LAR = 0xC5ACCE55;  // software unlock
  DWT->CYCCNT = 1;
  DWT->CTRL |= DWT_CTRL_CYCCNTENA_Msk;
}
\end{minted}
    \captionof{listing}{Aktivierung der DWT \cite{StackOverflow_DWT_Activation}}
    \label{code:dwt_activate_conf}
\end{code}

Danach kann die aktuelle Zyklenzahl direkt über \mintinline{cpp}|DWT->CYCCNT|
ausgelesen werden.

Drei wesentliche Informationen werden bei der Aufzeichnung von Zyklenstempeln
erfasst: der Identifikator der zugehörigen Task oder Funktion, die aktuelle
Zyklenzahl sowie ein Marker, der Beginn oder Ende einer Dauer kennzeichnet.
Diese Daten werden in einer Struktur (\ref{code:cycle_stamp_struct})
gespeichert.

\begin{code}
\begin{minted}{cpp}
struct cycle_stamp {
  const char* name;
  size_t cycle;
  bool is_begin;

  static inline uint32_t initial_cycle = 0;
};
\end{minted}
    \captionof{listing}{Definition des Zyklenstempels}
    \label{code:cycle_stamp_struct}
\end{code}

Die statische Variable speichert zur Laufzeit die Zyklenzahl zu Beginn eines
Samplings und dient als Referenzpunkt zur Normalisierung der Messwerte.

FreeRTOS bietet Makros (\ref{sec:trace_hooks}), die beim Kontextwechsel -- oder
genauer gesagt zu Beginn und auch beim Abschluss jedes FreeRTOS-Zeitabschnitts
(time slice) der aktuellen Task -- als Callbacks aufgerufen werden. Das Makro
\mintinline{cpp}|traceTASK_SWITCHED_IN()| wird aufgerufen, unmittelbar nachdem
eine Task zum Ausführen bzw. Fortfahren ausgewählt wurde.
\mintinline{cpp}|traceTASK_SWITCHED_OUT()| wird aufgerufen, unmittelbar bevor
der Programmfluss zu einer neuen Task gewechselt wird. An diesen Zeitpunkten
innerhalb vom Scheduling-Code enthält \mintinline{cpp}|pxCurrentTCB| -- die
interne Task-Control-Block-Struktur von FreeRTOS -- die Metadaten der aktuellen
Task, wodurch der Nutzer die Möglichkeit hat, direkt darauf als
Funktionsargument zuzugreifen. (\cite{freertos_rtos_trace_hooks})

Diese Makros (\ref{code:trace_hook_def}) werden somit jeweils als einen Aufruf
der Funktion \ref{code:task_switched_cb} mit dem Namen der aktuellen Task
(\mintinline{cpp}|pcTaskName|) und einer booleschen Variable als
Start/End-Marker definiert. Diese Funktion kann später in einer separaten
Übersetzungseinheit implementiert werden.

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin);
#define traceTASK_SWITCHED_IN() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 1)
#define traceTASK_SWITCHED_OUT() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 0)
\end{minted}
    \captionof{listing}{Konkrete Definition der Trace-Hook-Makros}
    \label{code:trace_hook_def}
\end{code}

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin) {
  if (!stamping_enabled) return;
  stamp(name, is_begin);
  ctx_switch_cnt += 1;
}
\end{minted}
    \captionof{listing}{Funktion zur Zyklenstempelgenerierung beim
    Kontextwechsel}
    \label{code:task_switched_cb}
\end{code}

Die Funktion überprüft zunächst, ob eine Aufzeichnung beim Kontextwechsel
durchgeführt werden soll, und ruft anschließend \mintinline{cpp}|stamp()| auf --
wenn dies der Fall ist. Nebenbei wird ein Zähler inkrementiert, der die
kumulierte Anzahl von Kontextwechsel repräsentiert.

Da das threadsichere Schreiben eines Zyklenstempels, welcher der aus mehreren
Bytes besteht, mittels Mutex schließlich eine blockierende Operation darstellt,
kann es nicht direkt in einer ISR erfolgen. Stattdessen müssen die erfassten
Daten zuerst in einen temporären Puffer geschrieben werden
(\ref{code:stamp_impl}).

\begin{code}
\begin{minted}{cpp}
inline constexpr size_t STAMP_BUF_SIZE = 512;
inline cycle_stamp stamps[STAMP_BUF_SIZE]{};
volatile inline std::atomic<size_t> stamp_idx = 0;
volatile inline bool stamping_enabled = false;

inline void stamp(const char* name, bool is_begin) {
  volatile auto cycle = DWT->CYCCNT;
  volatile auto idx = stamp_idx.fetch_add(1);
  stamps[idx % STAMP_BUF_SIZE] = {name, cycle, is_begin};
}
\end{minted}
    \captionof{listing}{Temporärpuffer mit dessen atomaren Schreibzeiger und
    Aktivierungsflag}
    \label{code:stamp_impl}
\end{code}

Der Schreibindex wird dabei als Variable vom Typ
\mintinline{cpp}|std::atomic<size_t>| definiert, um eine atomare Inkrementierung
mit gleichzeitiger Rückgabe des vorherigen Wertes zu ermöglichen.

% Standardmäßig nutzt \mintinline{cpp}|fetch_add()|
% \mintinline{cpp}|std::memory_order_seq_cst| als Wert für das letzte, optionale
% Argument zum Zweck der Speichersynchronisation (Memory-Barrier)
% \cite{cppreference_fetch_add}. Diese Option entspricht
% \mintinline{cpp}|__sync_synchronize()| aus C und fungiert als vollständige
% Memory-Barrier-Anweisung~\cite{gnu_atomic_builtins}, bei der weder
% Speicheroperationen noch Befehle relativ zu ihrer Position in der
% Ausführungsreihenfolge hardwareseitig umgeordnet werden können
% \cite{stackoverflow_stdatomic}. Konkret bedeutet dies: Alle Operationen
% \textit{vor} einer vollständigen Memory-Barrier-Anweisung müssen abgeschlossen
% sein, bevor Operationen \textit{nach} der Barriere ausgeführt werden können
% \cite{cppreference_memory_order}. Damit wird genau festgelegt, in welcher
% Reihenfolge die Speicherzugriffe sowohl innerhalb des eigenen Threads als auch
% in Bezug auf andere Threads erfolgen müssen.
%
% Dadurch wird sichergestellt, dass die Zyklenzahl immer vor dem Inkrement des
% Schreibindexes erfasst wird. Dies verhindert beispielsweise, dass ein Thread die
% Zyklenzahl vor dem Inkrement zwischenspeichert, während ein anderer Thread sie
% erst nach dem Inkrement erfasst, was zu einer fehlerhaften Reihenfolge führen
% würde.

Die erfassten ISR-Zyklenstempel müssen dann zusätzlich von einer FreeRTOS-Task
(\ref{freertos_output_task}) in ein menschenlesbares Format umgewandelt und in
die Senke geschrieben werden.

\begin{code}
    \begin{minted}{cpp}
static size_t prev_idx = 0;
auto output_stamps = []() static {
  auto end = stamp_idx;
  while (prev_idx != end) {
    const auto& [name, cycle, is_begin] = stamps[normalized_index(prev_idx++)];
    write_blocking(
        buf,
        snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                 cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
  }
};
    \end{minted}
    \captionof{listing}{Callback zur Ausgabe von ISR-Zyklenstempeln}
    \label{freertos_output_task}
\end{code}

Für Nicht-ISR-Kontexte ist die Funktion (\ref{code:stamp_direct_impl}) zur
direkten Ausgabe eines Zyklenstempels wie folgt definiert:

\begin{code}
\begin{minted}{cpp}
inline void stamp_direct(const char* name, bool is_begin) {
  char buf[50];
  volatile auto cycle = DWT->CYCCNT;
  tsink::write_blocking(
      buf, snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                    cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
}
\end{minted}
    \captionof{listing}{Funktion zur Ausgabe von Zyklenstempeln}
    \label{code:stamp_direct_impl}
\end{code}

Das RAII-Konzept (\ref{code:stamp_raii}) kommt ebenfalls hier zur Anwendung:
Beim Erstellen eines Objekts dieses Typs wird automatisch die Funktion
\ref{code:stamp_direct_impl} aufgerufen, beim Zerstören erneut.

\begin{code}
\begin{minted}{cpp}
struct cycle_stamp_raii {
  cycle_stamp_raii(const char* name) : name{name} {
    if (stamping_enabled) stamp_direct(name, true);
  }
  ~cycle_stamp_raii() {
    if (stamping_enabled) stamp_direct(name, false);
  }
  const char* name;
};

\end{minted}
    \captionof{listing}{Funktion zur Ausgabe von Zyklenstempeln}
    \label{code:stamp_raii}
\end{code}

Anhand des Beispiels \ref{code:raii_example} kann das RAII-Konzept strukturell
veranschaulicht werden.

\begin{code}
\begin{minted}{cpp}
void func()
{ // --> t1 stamp in
  cycle_stamp_raii t1{"func"};

  { // --> t2 stamp in
    cycle_stamp_raii t2{"code block"};
  } // --> t2 stamp out

} // --> t1 stamp out
\end{minted}
    \captionof{listing}{Beispielnutzung einer RAII-Struktur}
    \label{code:raii_example}
\end{code}

\paragraph{Zeitliche Garantie der Erstellung}

Unmittelbar nach der Erstellung eines solchen RAII-Objekts sollte ein
sogenanntes Memory-Barrier (\ref{code:memory_barrier}) erfolgen. Damit wird
sichergestellt, dass das Objekt tatsächlich zum definierten Zeitpunkt erstellt
wird und nicht durch Hardwareoptimierungen umgeordnet wird
\cite{arm_mem_barrier}, was aufgrund des schwachen Speichermodells (weak memory
ordering) der ARM-Architektur möglich wäre \cite[S. 5]{arm_sync_overview}.

\begin{code}
\begin{minted}{cpp}
volatile freertos::cycle_stamp_raii _{"p_ctrl"};
std::atomic_thread_fence(std::memory_order_seq_cst);
\end{minted}
    \captionof{listing}{RAII-basierter Zyklenstempel mit Memory-Barrier}
    \label{code:memory_barrier}
\end{code}

Softwareseitig lässt sich das Schlüsselwort \mintinline{cpp}|volatile| nutzen,
um die beabsichtigte Ausführungsreihenfolge auch bei aktivierten
Compileroptimierungen wie \mintinline{text}|-Os| zu erzwingen.

\paragraph{Zeitliche Garantie von Destruktor-Aufruf}

Der Aufruf von Destruktoren mit „Side Effects”\footnote{Zu „Side Effects” zählen
unter anderem Schreibzugriffe von Objekten sowie Schreib- und Lesezugriffe auf
ein \mintinline{cpp}|volatile|-Objekt.~\cite{cppreference_eval_order}} wird
nicht durch Optimierung eliminiert und erfolgt garantiert am Ende des
Ausführungsblocks, selbst wenn das Objekt nicht genutzt zu sein
scheint~\cite[§6.7.5.4 Abs. 3]{iso_iec_14882_2020}, und zwar immer in der
umgekehrten Reihenfolge, wie die Objekte erzeugt worden sind
\cite{isocpp_dtor_order}.

Durch die oben beschriebenen Maßnahmen lässt sich somit sicherstellen, dass die
Erzeugung von Zyklenstempeln in Nicht-ISR-Kontexten ebenfalls zur Echtzeit
erfolgt.

\subsection{Streaming-Mode via Button}

Laut Benutzerhandbuch des Boards ist der User-Button standardmäßig mit dem
I/O-Pin PC13 verbunden, was der \ac{EXTI}-Linie 13 entspricht. Praktischerweise
muss in STM32CubeMX nur die Option für EXTI-Line-Interrupts der Linien 10 bis 15
unter \textit{System Core/NVIC} aktiviert werden, sodass der Button bei jedem
Druck einen Interrupt auslöst.

Im entsprechenden Interrupt-Callback (\ref{code:btn_irq}) wird ein
Toggle-Mechanismus implementiert: Bei jedem Auslösen wird die boolesche Variable
\mintinline{cpp}|stamping_enabled| invertiert. Gleichzeitig wird die
Profiling-Task benachrichtigt, um die ISR-Zyklenstempel in die Senke zu
schreiben.

\begin{code}
\begin{minted}{cpp}
void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) {
  static constexpr uint8_t DEBOUNCE_TIME_MS = 100;
  static volatile uint32_t last_interrupt_time = 0;

  if (GPIO_Pin != USER_Btn_Pin) return;

  uint32_t current_time = HAL_GetTick();
  if (current_time - std::exchange(last_interrupt_time, current_time) >
      DEBOUNCE_TIME_MS) {
    stamping_enabled ^= 1;
    if (stamping_enabled) {
      stamp_idx = 0;
      cycle_stamp::initial_cycle = DWT->CYCCNT;

      static BaseType_t xHigherPriorityTaskWoken;
      vTaskNotifyGiveFromISR(profiling_task_hdl, &xHigherPriorityTaskWoken);
      portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
    }
  }
}
\end{minted}
    \captionof{listing}{Interrupt-Callback für den User-Button}
    \label{code:btn_irq}
\end{code}

Um ungewollte Mehrfachauslösungen durch unpräzises Drücken zu vermeiden, ist
eine kurze Debounce-Zeit notwendig.

\subsection{Exkurs: Laufzeitdaten -- Überblick}

Die Laufzeit- bzw. Profiling-Daten werden im menschenlesbaren Format ausgegeben.
Sie bestehen aus:

\begin{quote}
    \mintinline{text}|<Identifikator> <konvertierte Zeit> <Start-/End-Marker>|
\end{quote}

Die Zyklenzahlen werden dabei in Mikrosekunden umgewandelt, indem man sie durch
die Taktfrequenz teilt und auf die gewünschte Genauigkeit mit $1.000.000$
multipliziert.

Die Profiling-Daten (\ref{code:profiling_data}) folgen nicht einer aufsteigenden
Reihenfolge nach den konvertierten Zeitpunkten, da die ISR-Zyklenstempel erst
zwischengespeichert und später durch eine FreeRTOS-Task in einer frei wählbaren
Frequenz ausgegeben werden müssen. Da jedoch jeder Zyklenstempel in einer ISR
zur Echtzeit ohne Verzögerung erzeugt wird, spiegelt die zugehörige Zyklenzahl
und somit auch der konvertierte Zeitpunkt den tatsächlichen Echtzeitaspekt des
Systems korrekt wider. Daher ist eine strikt geordnete Ausgabe nicht zwingend
erforderlich.

\begin{code}
\begin{minted}{cpp}
IDLE 1 0        << mittels FreeRTOS-Task periodisch ausgegeben
profile 2 1     << mittels FreeRTOS-Task periodisch ausgegeben
w_ctrl 7413 1   << in Echtzeit ausgegeben
w_ctrl 7504 0   << in Echtzeit ausgegeben
odom 7951 1     << in Echtzeit ausgegeben
odom 7969 0     << in Echtzeit ausgegeben
profile 28 0    << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 29 1       << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 332 0      << mittels FreeRTOS-Task periodisch ausgegeben
tsink 333 1     << mittels FreeRTOS-Task periodisch ausgegeben
tsink 336 0     << mittels FreeRTOS-Task periodisch ausgegeben
...
\end{minted}
    \captionof{listing}{Ausschnitt der Profiling-Daten}
    \label{code:profiling_data}
\end{code}

Es wird versucht, die Ausgabe miteinander zu synchronisieren: Jeder Thread ruft
die Schreibfunktion der Senke mit einem globalen atomaren Zähler auf. Dieser
wird dann mit dem internen Zähler verglichen. Stimmen die Werte überein, wird
die Schreiboperation ausgeführt, andernfalls blockiert. Dieser Ansatz erweist
sich als nicht erfolgreich, da sich die resultierende Systemleistung durch das
nicht-deterministische Scheduling ohne Threadbevorzugung ungefähr um die Hälfte
senkt.

Anschließend wird versucht, alle Zyklenstempel vorab in dem Zwischenpuffer zu
speichern. Damit wird das Erzeugen und Ausgeben von Zyklenstempeln komplett
voneinander getrennt. Mit diesem Ansatz kann die Reihenfolge
(\ref{code:profiling_data_ordered}) konsistent gehalten werden. Allerdings führt
diese Lösung dazu, dass der Multithreaded-Aspekt der Queue bzw. Senke nicht mehr
benötigt wird, da alle Daten nun von einem einzigen Producer stammen. Die Senke
wird aber weiterhin zur Ausgabe verwendet und funktioniert auch in diesem
Kontext technisch korrekt.

\begin{code}
\begin{minted}{cpp}
IDLE 1 0
profile 2 1
profile 28 0
IDLE 29 1
IDLE 556 0
tsink 557 1
tsink 560 0
uros 561 1
uros 623 0
IDLE 625 1
IDLE 667 0
...
odom 6613 1
odom 6694 0
\end{minted}
    \captionof{listing}{Profiling-Daten in aufsteigender Reihenfolge}
    \label{code:profiling_data_ordered}
\end{code}

Zusammenfassend zeigt sich, dass sich mit der DWT, FreeRTOS-Trace-Hooks sowie
RAII-basierter Zyklenstempelerfassung in Kombination mit dem vorhandenen
User-Button eine leichtgewichtige Profiling-Methode für FreeRTOS-Tasks und
Codeabschnitte implementieren lässt.
