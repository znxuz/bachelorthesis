\section{Implementierung für die Echtzeitanalyse}

Nachdem die Steuerungssoftware für FreeRTOS und Micro-ROS entwickelt wurde, kann
nun die Methode zur Analyse der Echtzeitfähigkeit implementiert werden. Diese
basiert zunächst auf FreeRTOS, um später die Portierung auf Micro-ROS zu
ermöglichen.

Ziel der Analyse ist es, die Ausführungszeit einer bestimmten Task oder
zeitkritischen Funktion zu messen. Die erfassten Daten müssen präzise genug
sein, um die Echtzeitanforderungen zuverlässig abzubilden.

Aus Gründen der Einfachheit und aufgrund von Hardwarebeschränkungen wurde UART
als Schnittstelle zur Übertragung der Echtzeitdaten vom Mikrocontroller zum Host
gewählt. Mit einer theoretischen Übertragungsrate von bis zu 12,5 Mbit/s bietet
UART genügend Bandbreite~\cite[S. 2]{stm32_datasheet}, um die Echtzeitdaten
ohne Überlastung zu übertragen.

Der Ansatz basiert darauf, zu Beginn und am Ende der jeweiligen Task sowie der
zeitkritischen Funktion die aktuelle Zyklenzahl zu erfassen. Daraus lassen sich
die Echtzeitinformationen ableiten.

Daraus ergibt sich als Erstes die Notwendigkeit, eine threadsichere
Multi-Producer-Senke, oder besser gesagt eine \ac{MPSC} Queue, zu
implementieren, welche die Echtzeitdaten kontinuierlich konsumiert und sie über
UART ausgibt. Die vorhandenen FreeRTOS-Stream- oder Messagebuffer eignen sich
nicht für mehrere Producer~\cite{FreeRTOSStreamBuffer} und können in dem Fall
nicht verwendet werden.

\subsection{Multi-Producer-Senke}

Da FreeRTOS und folglich auch Micro-ROS von Natur aus mehrfädig sind und bei der
Echtzeitanalyse Daten von beliebiger Stelle in einem beliebigen Thread während
des Programmablaufs aufgezeichnet werden, muss die Threadsicherheit
gewährleistet werden. Dadurch wird verhindert, dass die zu übertragenden Daten,
die aus mehreren Bytes bestehen, durch Race Conditions teilweise überschrieben
und somit unbrauchbar werden.

Die grundlegende Idee besteht darin, dass Daten von mehreren Threads direkt in
die Senke geschrieben -- oder präziser formuliert in einen internen Ringpuffer
gespeichert werden. Das Schreiben der Daten in einen statischen Speicherpuffer
ist wesentlich schneller als beispielsweise das Einreihen in eine verkettete
Liste, da letzteres eine dynamische Heap-Speicherallokation erfordert.

Da der vorallokierte Speicher begrenzt ist, muss die Senke im schlimmsten Fall
erkennen können, wann sie das weitere Schreiben von Daten in den Puffer
blockieren muss. Dadurch wird verhindert, dass noch nicht verarbeitete, aber
bereits geschriebene Daten überschrieben werden.

Aber durch die Verwendung von DMA kombiniert mit Interrupts ausgelöst bei jedem
Abschluss einer DMA-Übertragung kann die IO-gebundene Wartezeit zum Verbrauchen
von Bytes in der Senke eliminiert werden, da in diesem Fall die tatsächliche
Ausgabe von Daten aus der Senke einfach zum Schreiben in einen anderen
In-Memory-Puffer wird, während die eigentlichen IO-Operationen auf den
DMA-Controller fern vom Prozessor ausgelagert werden. Wenn die tatsächliche IO
die Daten schnell genug überträgt, um mit den eingehenden Daten Schritt zu
halten, entsteht dabei keine Situation, in der eine Task blockiert werden muss,
dass die Senke Speicherplatz freigibt, um den Schreibvorgang fortzusetzen.

Daher wurde als Ansatz eine Multi-Producer-Senke mit DMA-Implementierung
gewählt, da in diesem Fall das Schreiben mehrerer Bytes in die Senke
idealerweise nur wenige Zyklen benötigt und sich aus Sicht des Prozessors bzw.
Threads nahezu als nicht-blockierende Operation verhält.

\subsubsection{Aufbau}

Wie kurz erwähnt, besteht die Senke einfacherweise hauptsächlich aus einem
statisch vorallokierten Ringpuffer gepaart mit einem Schreib- und Lesezeiger.
Mit den beiden Zeigern wird dann ermöglicht, die Größe der bereits geschriebenen
Daten sowie der restliche verfügbare Speicherplatz zu ermitteln.

In der ersten Implementierungsversion wurde die verfügbare Datenmenge in der
Senke so berechnet, dass sie der Differenz zwischen Schreib- und Lesezeiger
entspricht, wenn sich der Schreibindex numerisch vor dem Leseindex befindet.
Andernfalls umfassen die zu verarbeitenden Daten die Sequenz vom Lesezeiger bis
zum Ende des Ringpuffers sowie vom Anfang des Puffers bis zum Schreibzeiger, da
die Zeiger stets korrekt positioniert sind.

Dabei musste aber auch zwischen dem Fall unterschieden werden, wenn beide Zeiger
gleichzeitig auf dieselbe Position zeigen: entweder ist der Ringpuffer leer,
oder komplett voll beschrieben. Daher muss der Schreiber erkennen können, ob das
aktuelle Byte bereits verarbeitet wurde und somit überschrieben werden darf.
Andernfalls lässt sich nicht feststellen, ob die Senke voll ist und das
Schreiben verzögert werden muss.

In einem C++-Konferenzvortrag über eine
\ac{MPMC}-Warteschlange~\cite{CppCon2024LockFreeQueue} basiert die
Implementierung auf folgendem Prinzip: Jede Position des Datenpuffers besitzt
eine eindeutige Schreibsequenznummer. Bei der Datenentnahme wird diese atomar um
die Gesamtlänge N des Puffers erhöht. Dadurch wird signalisiert, dass die Daten
dieser Position in Iteration N verarbeitet wurden und in Iteration N+1 vom
Schreiber überschrieben werden können. Die Entscheidung hierüber erfolgt durch
Vergleich mit der globalen Schreibsequenznummer, die ebenfalls nach jedem
Schreibvorgang atomar inkrementiert wird.

Für den Fall einer Senke mit nur einem einzigen Verbraucher genügt es, den
Zustand als \mintinline{cpp}|bool| zu speichern. Dieser gibt an, ob die Daten an
einer bestimmten Position noch verarbeitet werden müssen oder bereits
überschrieben werden können.

Um den zusätzlichen Speicherbedarf -- verursacht durch die explizite
Zustandsmarkierung jedes Bytes im Puffer -- in der finalen Implementierung zu
eliminieren, können die Zeiger auf eine stets korrekte Position verzichten.
Stattdessen können sie einfach über den Puffer hinaus zählen. Bei jeder
Verwendung wird ihr Wert durch eine Modulo-Operation mit der Puffergröße
normalisiert, wodurch sie dann auf die korrekte Position verweisen. Demnach
reduziert sich die Berechnung der verfügbaren Datenmenge auf eine einfache
Subtraktion zwischen beiden Zeigern.

Wenn die Puffergröße einer Zweierpotenz entspricht, lässt sich die
Modulo-Operation ebenfalls auf einen einzigen Zyklus reduzieren. Dieser geringe
Mehraufwand stellt ein akzeptables Trade-off dar -- insbesondere im Vergleich
zum eingesparten Speicherplatz für die Zustandsinformation.

\begin{code}
\begin{minted}{cpp}
#ifndef TSINK_CAPACITY
constexpr size_t TSINK_CAPACITY = 2048;
#endif
uint8_t sink[TSINK_CAPACITY]{};
volatile size_t read_idx = 0;
std::atomic<size_t> write_idx = 0;

size_t size() { return write_idx - read_idx; }
size_t space() { return TSINK_CAPACITY - size(); }
size_t normalize(size_t idx) { return idx % TSINK_CAPACITY; }
\end{minted}
    \captionof{listing}{Implementierung der Senke}
\end{code}

\subsubsection{Schreibvorgang in die Senke}

Auf ARM-Architekturen sind alle Zugriffe auf Bytes, Halbwörter (16-Bit) und
Wörter (32-Bit) standardmäßig atomar sofern sie im Speicher ausgerichtet sind,
und verursachen dabei keine Schreib-Lese-Konflikte, sowohl beim Lesen als auch
beim Schreiben~\cite[S. A3-79]{ARM_DDI0403_EE}.

Es muss jedoch sichergestellt werden, dass immer nur ein einziger Thread
an eine Position des Ringpuffers schreiben kann, wenn mehrere
Threads gleichzeitig auf dieselbe Position zugreifen wollen.

Hier kann eine \ac{CAS}-Operation eingesetzt werden, um sicherzustellen, dass
der Schreibindex bei gleichzeitigen Zugriffen mehrerer Threads stets nur von
einem Thread inkrementiert wird. Nach erfolgreicher Inkrementierung erhält
dieser Thread das Recht, das Byte an der vorherigen Indexposition zu
beschreiben.

\begin{code}
\begin{minted}{cpp}
bool write_or_fail(uint8_t elem) {
  auto expected = write_idx.load();
  if (expected - read_idx == TSINK_CAPACITY) return false;
  if (write_idx.compare_exchange_strong(expected, expected + 1)) {
    sink[normalize(expected)] = elem;
    return true;
  }
  return false;
}
\end{minted}
    \captionof{listing}{atomare Schreiboperation in die Senke}
\end{code}

Die Vorgehensweise gestaltet sich wie folgt: Zunächst wird der aktuelle
Schreibindex als lokale Variable \mintinline{cpp}|expected| zwischengespeichert.
Dann wird erstmal überprüft, ob der Puffer bereits voll ist -- in diesem Fall
wird vorzeitig zurückgekehrt, andernfalls ist die Position mit dem aktuellen
Index noch beschreibbar. Anschließend erfolgt die atomare CAS-Operation, bei der
der Schreibindex mit dem zwischengespeicherten Wert verglichen und bei
Übereinstimmung um eins inkrementiert wird. Durch diese atomare Operation, die
Vergleich und Inkrement verbindet, kann nur ein Thread den Schreibindex
erfolgreich erhöhen und Daten über den zwischengespeicherten Index schreiben.
Die Synchronisation erfolgt somit auf nicht-blockierende (lock-free) Weise.

Um auch das Schreiben mehrerer Bytes ebenfalls threadsicher zu gestalten, muss
ein Mutex zum Einsatz kommen~\cite{FreeRTOSForumPrintf}. Im Gegensatz zu einem
einfachen Semaphor stellt dies sicher, dass ein Thread den Mutex
schnellstmöglich wieder freigibt und nicht vom Scheduler ausgeschlossen wird
(\ref{sec:mutex}).

Die Struktur \mintinline{cpp}|struct mtx_guard| ist hier implementiert. Sie
nutzt \ac{RAII}, um beim Erstellen eines Objekts automatisch den Mutex zu
sperren und ihn beim Verlassen des Gültigkeitsbereichs -- in diesem Fall beim
Verlassen des \mintinline{cpp}|if|-Blocks -- wieder freizugeben. Falls nicht
genügend Platz in der Senke vorhanden ist, wird kooperativ der Kontrollfluss für
eine Millisekunde an den Scheduler zurückgegeben, um andauerndes Polling zu
vermeiden.

\begin{code}
\begin{minted}{cpp}
struct mtx_guard {
  mtx_guard() { configASSERT(xSemaphoreTake(write_mtx, portMAX_DELAY)); }
  ~mtx_guard() { configASSERT(xSemaphoreGive(write_mtx)); }
};

void write_blocking(const uint8_t* ptr, size_t len) {
  while (true) {
    if (volatile auto _ = mtx_guard{}; space() >= len) {
      for (size_t i = 0; i < len; ++i) configASSERT(write_or_fail(ptr[i]));
      return;
    }
    vTaskDelay(pdMS_TO_TICKS(1));
  }
}
\end{minted}
    \captionof{listing}{Blockierende Schreiboperation in die Senke}
\end{code}

\subsubsection{Lesevorgang aus der Senke}

Eine kleine, statisch allokierte FreeRTOS-Task wird erstellt, um kontinuierlich
zu versuchen, verfügbare Daten aus der Senke zu entnehmen und verarbeiten.

\begin{code}
\begin{minted}{cpp}
using consume_fn = void (*)(const uint8_t*, size_t);
consume_fn consume;

void task_impl(void*) {
  auto consume_and_wait = [](size_t pos, size_t size) static {
    if (!size) return;
    consume(sink + pos, size);
    ulTaskNotifyTake(pdFALSE, portMAX_DELAY);
  };

  while (true) {
    if (size_t sz = size(); sz) {
      auto idx = normalize(read_idx);
      auto wrap_around = ((idx + sz) / TSINK_CAPACITY) *  // multiplier as bool
                         ((idx + sz) % TSINK_CAPACITY);   // actual amount
      auto immediate = sz - wrap_around;
      consume_and_wait(idx, immediate);
      consume_and_wait(0, wrap_around);
      read_idx += sz;
    } else {
      vTaskDelay(pdMS_TO_TICKS(1));
    }
  }
}
\end{minted}
    \captionof{listing}{Implementierung der Task zur Datenverarbeitung}
\end{code}

Zunächst wird die Größe der verfügbaren Daten vom Beginn des Ringpuffers bis zum
Schreibindex mathematisch berechnet, sofern vorhanden, sowie die Größe vom
Leseindex bis zum Pufferende, oder nur bis zum Schreibindex. Bei jedem Aufruf
wartet \mintinline{cpp}|ulTaskNotifyTake()| auf den Abschluss der aktuellen
IO-Operation, bevor eine neue gestartet werden kann -- falls die Operation noch
nicht abgeschlossen ist.

Diese Vorgehensweise ist notwendig wenn \mintinline{cpp}|consume()| DMA nutzt:
Die DMA-API zur Übertragung von der STM32-HAL signalisiert dabei lediglich der
Hardware den gewünschten Transfervorgang und kehrt sofort
zurück~\cite{HAL_UART_Transmit_DMA}. Das heißt, die Daten werden einfach zur
Verarbeitung für den DMA eingereiht, während der Programmfluss unmittelbar
fortgesetzt wird. Außerdem ist das globale, intern genutzte UART-Zustandsobjekt
auch nicht wiedereintrittsfähig\footnotemark{} \cite{stm32_hal_reentrancy}.
Daher müssen subsequente Aufrufe hierbei miteinander synchronisiert werden.

\footnotetext{„Als wiedereintrittsfähig -- zu englisch reentrant -- wird ein
Programm-Attribut beschrieben, welches die mehrfache (quasi-gleichzeitige)
Nutzung eines Programm-Codes erlaubt, so dass sich gleichzeitig (oder
quasi-gleichzeitig) ausgeführte Instanzen nicht gegenseitig
beeinflussen.”~\cite{wiedereintrittsfaehigkeit}}

Als Verbrauchsfunktion \mintinline{cpp}|consume()| kann beispielsweise die
HAL-API von STM32 für DMA-Übertragungen verwendet werden. Diese nimmt einen
Zeiger auf ein Array sowie die Größe der lesbaren Daten als Parameter entgegen.

\begin{code}
\begin{minted}{cpp}
auto tsink_consume_dma = [](const uint8_t* buf, size_t size) {
  HAL_UART_Transmit_DMA(&huart3, buf, size);
}
\end{minted}
    \captionof{listing}{Beispieldefinition einer Verbrauchsfunktion}
    \label{code:consume_fn}
\end{code}

Erst wenn eine Task-Notifikation durch \mintinline{cpp}|consume_complete()|
eintrifft -- ausgelöst durch eine \ac{ISR} der DMA-Hardware nach
Übertragungsende -- wird die Task wieder entblockt, um weitere IO-Operationen zu
initiieren.

\begin{code}
\begin{minted}{cpp}
enum struct CALL_FROM { ISR, NON_ISR };

template <CALL_FROM callsite>
void consume_complete() {
  using namespace detail;
  if constexpr (callsite == CALL_FROM::ISR) {
    static BaseType_t xHigherPriorityTaskWoken;
    vTaskNotifyGiveFromISR(task_hdl, &xHigherPriorityTaskWoken);
    portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
  } else {
    xTaskNotifyGive(task_hdl);
  }
}
\end{minted}
    \captionof{listing}{Callback-Funktion für die Task-Notifikation}
\end{code}

\subsubsection{Nutzung der Senke mit DMA}

Für die Nutzung dieser Senke mit DMA und aktiviertem Datencache muss zunächst
das Interrupt-Callback \mintinline{cpp}|HAL_UART_TxCpltCallback()| definiert
werden, das nach jedem DMA-Transfer ausgelöst wird.

Die Initialisierungsfunktion der Senke muss dann aufgerufen werden. Diese nimmt
einen Funktionszeiger vom Typ \mintinline{cpp}|consume_fn| zur cache-kohärenten
Datenverarbeitung (\ref{code:cache_clean}) sowie eine Priorität für die interne
Verbraucher-Task als Argumente entgegen.

\begin{code}
\begin{minted}{cpp}
void HAL_UART_TxCpltCallback(UART_HandleTypeDef* huart) {
  if (huart->Instance == huart3.Instance)
    tsink::consume_complete<tsink::CALL_FROM::ISR>();
}

void main() {
  auto tsink_consume_dma = [](const uint8_t* buf, size_t size) static {
    auto flush_cache_aligned = [](uintptr_t addr, size_t size) static {
      constexpr auto align_addr = [](uintptr_t addr) { return addr & ~0x1F; };
      constexpr auto align_size = [](uintptr_t addr, size_t size) {
        return size + ((addr) & 0x1F);
      };

      SCB_CleanDCache_by_Addr(reinterpret_cast<uint32_t*>(align_addr(addr)),
                              align_size(addr, size));
    };

    flush_cache_aligned(reinterpret_cast<uintptr_t>(buf), size);
    HAL_UART_Transmit_DMA(&huart3, buf, size);
  };
  tsink::init(tsink_consume_dma, osPriorityAboveNormal);
}
\end{minted}
    \captionof{listing}{Initialisierung der Senke mit DMA}
\end{code}

\subsubsection{Nutzung der Senke mit blockierender IO}

Ähnlich wie bei der Initialisierung über DMA, entfällt hier aber der
Interrupt-Callback, und die Funktion zur Datenverarbeitung wird durch die
Verwendung der blockierenden API ohne Leerung von Cache vereinfacht, da ohne DMA
keine manuelle Sicherstellung der Cache-Kohärenz notwendig ist.

\begin{code}
\begin{minted}{cpp}
int main() {
  auto tsink_consume = [](const uint8_t* buf, size_t size) static {
    HAL_UART_Transmit(&huart3, buf, size, HAL_MAX_DELAY);
    tsink::consume_complete<tsink::CALL_FROM::NON_ISR>();
  };

  tsink::init(tsink_consume, osPriorityAboveNormal);
}
\end{minted}
    \captionof{listing}{Initialisierung der Senke mit blockierender IO}
\end{code}

\subsubsection{Benchmark}

Ein Benchmark für die Senke wurde entwickelt, um deren Leistung unter paralleler
Last zu testen. Der Benchmark lässt eine Anzahl von
\mintinline{text}|BENCHMARK_N = 5| Threads gleichzeitig laufen, die jeweils eine
Anzahl von \mintinline{cpp}|iteration = 5000| Nachrichten mit ca. 80 Charaktern
nach Formatierung hintereinander über die Senke ausgeben.

Nach Abschluss des Benchmarks werden die gemessenen Zeiten und die
Laufzeitstatistiken der jeweiligen Task ausgegeben.

\begin{minipage}[t]{0.5\textwidth}
    \begin{code}
        \begin{minted}[linenos=false]{cpp}
time in ms: 7576
time in ms: 8071
time in ms: 9064
time in ms: 9386
time in ms: 9571
===================================
Task            Time            %%
print_bench     0               <1%
IDLE            72844           76%
benchmark       4385            4%
benchmark       4221            4%
benchmark       4374            4%
benchmark       4470            4%
benchmark       4169            4%
tsink           312             <1%
Tmr Svc         0               <1%
    \end{minted}
        \captionof{listing}{Benchmark mit DMA}
    \end{code}
\end{minipage}
\hfill
\begin{minipage}[t]{0.5\textwidth}
    \begin{code}
        \begin{minted}[linenos=false]{cpp}
time in ms: 10964
time in ms: 11016
time in ms: 11285
time in ms: 11379
time in ms: 11405
===================================
Task            Time            %%
print_bench     0               <1%
IDLE            0               <1%
benchmark       3624            3%
benchmark       3637            3%
benchmark       3623            3%
benchmark       3644            3%
benchmark       3631            3%
tsink           94876           83%
Tmr Svc         0               <1%
    \end{minted}
        \captionof{listing}{Benchmark mit blockierender IO}
    \end{code}
\end{minipage}

Die Ausgabe enthält zwei verschiedene Zeitmessungen für den Benchmark. Die erste
Messung erfasst die Zeitspanne vom Start der jeweiligen Task bis zu dessen
Beendigung. Die zweite Messung bezieht sich auf die
FreeRTOS-Laufzeitstatistiken, die durch \mintinline{cpp}|vTaskGetRunTimeStats()|
formatiert ausgegeben sind. Diese liefern die absolute, akkumulierte Zeit für
jede Task, die im Zustand „Running” verbracht hat, sowie deren prozentualen
Anteil an der Gesamtlaufzeit \cite{freertos_runtime_stats}.

Der Benchmark zeigt, dass asynchrone Übertragung per DMA die Gesamtlaufzeit des
Benchmark-Prozesses im Vergleich zur IO-gebundenen Variante um etwa $16\,\%$
verringerte, während gleichzeitig die IO-gebundene Zeit freigegeben wurde,
sodass sie von anderen Tasks genutzt werden kann.

Ebenso kann abgeleitet werden, dass durch die Verwendung von DMA die
Datenübertragungsrate nahezu das vorkonfigurierte Maximum der Baudrate von
$2.000.000\,\text{bps}$ erreicht wurde: Insgesamt wurden $1.908.759$ Bytes
übertragen, dabei hat ein UART-Frame per Byte eine standardmäßige Wortlänge von
8 Bit, inklusive je 1 Start- und 1 Stopp-Bit, ohne Paritätsbit.

\begin{align*}
    1.908.355\text{\,B} \times 10\text{\,b per Frame} =
    19.083.550 \text{\,b} = \text{Gesamte Bits}
\end{align*}

Teilt man dies durch die gesamte Übertragungszeit, ergibt sich die effektive
Bitrate sowie der prozentuale Anteil im Vergleich zur maximalen Baudrate:

\begin{align*}
    \text{Bitrate bei DMA} =
    \frac{19.083.550\text{\,b}}{9,571\text{\,s}} \approx
    1.993.893,01 \text{\,bps} \\
    \quad \Rightarrow 99,70\,\%\text{ des Maximums} \\
    \\
    \text{Bitrate bei blockierender IO} =
    \frac{19.083.550\text{\,b}}{11,405\text{\,s}} \approx
    1.673.261,73 \text{\,bps} \\
    \quad \Rightarrow 83,66\,\% \text{ des Maximums}
\end{align*}

Der Code für die Senke sowie den Benchmark befinden sich in den
Repositorys~\cite{freertos_threadsafe_sink, freertos_tsink_benchmark}.

\subsection{Aktivierung der DWT}

Wie im vorherigen Abschnitt \ref{sec:dwt} erläutert, eignet sich die DWT gut zur
Generierung von Echtzeitdaten in Form von Zyklenzahlen. Mittels der folgenden
Konfigurationsschritte kann diese Debug-Einheit aktiviert werden:

\begin{code}
\begin{minted}{cpp}
void enable_dwt() {
  CoreDebug->DEMCR |= CoreDebug_DEMCR_TRCENA_Msk;
  DWT->LAR = 0xC5ACCE55;  // software unlock
  DWT->CYCCNT = 1;
  DWT->CTRL |= DWT_CTRL_CYCCNTENA_Msk;
}
\end{minted}
    \captionof{listing}{Aktivierung der DWT \cite{StackOverflow_DWT_Activation}}
\end{code}

Danach kann die aktuelle Zyklenzahl direkt über \mintinline{cpp}|DWT->CYCCNT|
ausgelesen werden.

\subsection{Aufzeichnung von Zyklenstempeln}

Drei wesentliche Informationen werden bei der Aufzeichnung von Zyklenstempeln
erfasst: der Identifikator der zugehörigen Task oder Funktion, die aktuelle
Zyklenzahl sowie ein Marker, der Beginn oder Ende einer Dauer kennzeichnet.
Diese Daten werden in einer Struktur gespeichert.

\begin{code}
\begin{minted}{cpp}
struct cycle_stamp {
  const char* name;
  size_t cycle;
  bool is_begin;

  static inline uint32_t initial_cycle = 0;
};
\end{minted}
    \captionof{listing}{Definition des Zyklenstempels}
\end{code}

Die statische Variable speichert die Ausgangszyklenzahl zur Laufzeit und dient
lediglich als Referenzpunkt zur Normalisierung der Messwerte.

\subsubsection{Beim Kontextwechsel}

FreeRTOS bietet Makros (\ref{sec:trace_hooks}), die beim Kontextwechsel -- oder
genauer gesagt zu Beginn und auch beim Abschluss jedes FreeRTOS-Zeitabschnitts
(time slice) einer laufenden Task -- als Callbacks in einer ISR aufgerufen
werden können. Das Makro \mintinline{cpp}|traceTASK_SWITCHED_IN()| wird
aufgerufen, unmittelbar nachdem eine Task zum Ausführen oder Fortfahren
ausgewählt wurde. \mintinline{cpp}|traceTASK_SWITCHED_OUT()| wird aufgerufen,
unmittelbar bevor der Programmlauf zu einer neuen Task gewechselt wird. An
diesen Zeitpunkten innerhalb vom Scheduling-Code enthält
\mintinline{cpp}|pxCurrentTCB| -- der interne Task-Control-Block-Struktur von
FreeRTOS -- die Metadaten der aktuellen Task, wodurch der Nutzer die Möglichkeit
hat, direkt darauf als Funktionsargument zuzugreifen, um Informationen über die
gerade laufenden Task zu erlangen. (\cite{freertos_rtos_trace_hooks})

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin);
#define traceTASK_SWITCHED_IN() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 1)
#define traceTASK_SWITCHED_OUT() \
    task_switched_isr(pxCurrentTCB->pcTaskName, 0)
\end{minted}
    \captionof{listing}{Konkrete Definition der Trace-Hook-Makros in
    \texttt{FreeRTOSConfig.h}}
\end{code}

Hierbei werden die Makros jeweils als ein Aufruf der Funktion
\mintinline{cpp}|task_switched_isr()| mit dem Namen der aktuellen Task
\mintinline{cpp}|pcTaskName| sowie eine boolesche Variable als Start/End-Marker
definiert.

Das Feld \mintinline{cpp}|uxTaskNumber| vom Typ \mintinline{cpp}|unsigned long|
aus dem \mintinline{cpp}|pxCurrentTCB|-Objekt, das eigentlich speziell zur
Task-Identifizierung für Drittanbieter-Software konzipiert
ist~\cite{freertos_task_c_410}, kann in dem Fall auch als möglicherweise der
leichtgewichtigste Identifikator genutzt werden. Da das Ausgeben des
menschenlesbaren Namens keinen Bottleneck bei der IO-Übertragung verursacht und
man nicht nachträglich manuell jeden generierten Zyklenstempel der zugehörigen
Task zuordnen muss, wird hier einfachheitshalber auf den Namen entschieden.

\begin{code}
\begin{minted}{cpp}
void task_switched_isr(const char* name, uint8_t is_begin) {
  if (!stamping_enabled) return;
  stamp(name, is_begin);
  ctx_switch_cnt += 1;
}
\end{minted}
    \captionof{listing}{Zyklenstempelgenerierung beim Kontextwechsel}
\end{code}

Die Funktion überprüft zunächst, ob die Aufzeichnung beim Kontextwechsel
durchgeführt werden soll, und ruft anschließend \mintinline{cpp}|stamp()| auf --
wenn dies der Fall ist. Nebenbei wird ein Zähler inkrementiert, der die
akkumulierte Anzahl von Kontextwechsel repräsentiert.

Da das Schreiben eines Zyklenstempel bestehend aus mehreren Bytes in die Senke
gleichzeitig aus mehreren Threads per se nicht „lock-free“ sein kann, darf es
nicht direkt in einer ISR durchgeführt werden. Stattdessen müssen in
\mintinline{cpp}|stamp()| die Daten zuerst in einen temporären Puffer
geschrieben werden.

\begin{code}
\begin{minted}{cpp}
inline constexpr size_t ISR_STAMP_BUF_SIZE = 512;

inline std::array<cycle_stamp, STAMP_BUF_SIZE> isr_stamps{};
volatile inline size_t isr_stamp_idx = 0;
volatile inline bool stamping_enabled = 0;

void stamp(const char* name, bool is_begin) {
  volatile auto cycle = DWT->CYCCNT;
  volatile auto idx = stamp_idx.fetch_add(1);
  stamps[idx % STAMP_BUF_SIZE] = {name, cycle, is_begin};
}
\end{minted}
    \captionof{listing}{Temporärpuffer mit dessen atomaren Schreibzeiger und
    Aktivierungsflag}
\end{code}

Standardmäßig verwendet \mintinline{cpp}|fetch_add()|
\mintinline{cpp}|std::memory_order_seq_cst| als Wert für das letzte, optionale
Argument \cite{cppreference_fetch_add}. Diese Option entspricht
\mintinline{cpp}|__sync_synchronize()| aus der C-Welt und wirkt als vollständige
Memory-Barrier-Anweisung~\cite{cppreference_memory_order}, ähnlich dem starken
Speichermodell (strong memory model) bei x86-Plattformen, wo Operationen nicht
umgeordnet werden oder zumindest für andere Threads nicht umgeordnet
erscheinen \cite{memory_ordering}.

Die erfassten ISR-Zykluszahlen müssen dann zusätzlich von einer FreeRTOS-Task in
einen menschenlesbaren String umgewandelt und in die Senke geschrieben werden.

\begin{code}
    \begin{minted}{cpp}
static size_t prev_idx = 0;
auto output_stamps = []() static {
  auto end = stamp_idx;
  while (prev_idx != end) {
    const auto& [name, cycle, is_begin] = stamps[normalized_index(prev_idx++)];
    write_blocking(
        buf,
        snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                 cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
  }
};
    \end{minted}
    \captionof{listing}{Callback zur Ausgabe von ISR-Zyklenstempeln}
\end{code}

\subsubsection{Im Nicht-ISR-Kontext}

Für Nicht-ISR-Kontexte ist die Funktion zur direkten Ausgabe eines
Zyklusstempels wie folgt definiert:

\begin{code}
\begin{minted}{cpp}
inline void stamp_direct(const char* name, bool is_begin) {
  char buf[50];
  volatile auto cycle = DWT->CYCCNT;
  tsink::write_blocking(
      buf, snprintf(buf, sizeof(buf), "%s %u %u\n", name,
                    cycle_to_us(cycle - cycle_stamp::initial_cycle), is_begin));
  ;
}

struct cycle_stamp_raii {
  cycle_stamp_raii(const char* name) : name{name} {
    if (stamping_enabled) stamp_direct(name, true);
  }
  ~cycle_stamp_raii() {
    if (stamping_enabled) stamp_direct(name, false);
  }
  const char* name;
};
\end{minted}
    \captionof{listing}{Funktion zur Ausgabe von Zyklenstempeln}
\end{code}

Das RAII-Konzept kommt ebenfalls hier zur Anwendung: Beim Erstellen eines
Objekts dieses Typs wird automatisch \mintinline{cpp}|stamp_direct()|
aufgerufen, beim Zerstören -- beim Verlassen des Gültigkeitsbereichs -- erneut.
Dadurch markiert es Beginn und Ende eines zeitkritischen Abschnitts und
ermittelt dessen Dauer.

\begin{code}
\begin{minted}{cpp}
void func()
{ // --> t1 stamp in
  cycle_stamp_raii t1{"func"};
  { // --> t2 stamp in
    cycle_stamp_raii t2{"code block"};
  } // --> t2 stamp out
} // --> t1 stamp out
\end{minted}
    \captionof{listing}{Beispielnutzung einer RAII-Struktur}
\end{code}

Unmittelbar nach der Erstellung eines solchen RAII-Objekts sollte ebenfalls ein
Memory-Barrier erfolgen. Damit wird sichergestellt, dass das Objekt tatsächlich
zum definierten Zeitpunkt erstellt wird und nicht beispielsweise durch
Optimierungen umgeordnet wird, denn ARM-Architekturen verwenden standardmäßig
ein schwaches Speichermodell (weak/relaxed memory order).

\begin{code}
\begin{minted}{cpp}
freertos::cycle_stamp_raii _{"p_ctrl"};
std::atomic_thread_fence(std::memory_order_seq_cst);
\end{minted}
    \captionof{listing}{Generierung eines Zyklenstempels via eines RAII-Objekts}
\end{code}

Laut des ISO-C++-Standards aus dem Jahr 2020 wird der Aufruf von Destruktoren
mit „Side Effects”\footnotemark{} nicht durch Optimierung eliminiert und erfolgt
garantiert am Ende des Ausführungsblocks, selbst wenn das Objekt nicht genutzt
zu sein scheint~\cite[§6.7.5.4 Abs. 3]{iso_iec_14882_2020}, und zwar immer in
der umgekehrten Reihenfolge, wie die Objekte kreiert worden sind
\cite{isocpp_dtor_order}.

\footnotetext{Zu „Side Effects” zählen unter anderem Schreibzugriffe von
Objekten sowie Schreib- und Lesezugriffe auf ein
\mintinline{cpp}|volatile|-Objekt.~\cite{cppreference_eval_order}}

Durch die oben beschriebenen Maßnahmen lässt sich sicherstellen, dass die
Erzeugung von Zyklenstempeln in Nicht-ISR-Kontexten ebenfalls zur Echtzeit
erfolgt.

\subsection{Streaming-Mode via Button}

Laut Benutzerhandbuch des Boards ist der User-Button standardmäßig mit dem
I/O-Pin PC13 verbunden~\cite[S. 24, 6.6]{stm32_nucleo144_user_manual}, was der
EXTI-Linie 13 entspricht~\cite[S. 322, 11.8]{stm32f7_ref_manual}.
Praktischerweise muss in STM32CubeMX nur die Option für EXTI-Line-Interrupts der
Linien 10 bis 15 unter \textit{System Core/NVIC} aktiviert werden, sodass der
Button bei jedem Druck einen Interrupt auslöst.

Im entsprechenden Interrupt-Callback wird ein Toggle-Mechanismus implementiert:
Bei jedem Auslösen wird die boolesche Variable
\mintinline{cpp}|stamping_enabled| invertiert. Gleichzeitig wird die
Profiling-Task benachrichtigt, um die ISR-Zyklenstempel auszugeben.


\begin{code}
\begin{minted}{cpp}
void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) {
  static constexpr uint8_t DEBOUNCE_TIME_MS = 100;
  static volatile uint32_t last_interrupt_time = 0;

  if (GPIO_Pin != USER_Btn_Pin) return;

  uint32_t current_time = HAL_GetTick();
  if (current_time - std::exchange(last_interrupt_time, current_time) >
      DEBOUNCE_TIME_MS) {
    stamping_enabled ^= 1;
    if (stamping_enabled) {
      stamp_idx = 0;
      cycle_stamp::initial_cycle = DWT->CYCCNT;

      static BaseType_t xHigherPriorityTaskWoken;
      vTaskNotifyGiveFromISR(profiling_task_hdl, &xHigherPriorityTaskWoken);
      portYIELD_FROM_ISR(xHigherPriorityTaskWoken);
    }
  }
}
\end{minted}
    \captionof{listing}{Interrupt-Callback für den User-Button}
\end{code}

Um ungewollte Mehrfachauslösungen durch unpräzises Drücken zu vermeiden, ist
eine kurze Debounce-Zeit notwendig.

Zusammenfassend lässt sich festhalten, dass sich mithilfe von
FreeRTOS-Trace-Hooks sowie RAII-basierter Zyklenstempelerfassung -- kombiniert
mit dem vorhandenen User-Button -- ein leichtgewichtiges Profiling-System für
FreeRTOS-Tasks und zeitkritische Codeabschnitte realisieren lässt.

\subsection{Visualisierung von Profiling-Daten}

Die Profiling-Daten werden im menschenlesbaren Format \linebreak
\mintinline{text}|<Identifikator> <konvertierte Zeit> <Start-/End-Marker>|
umgerechnet in Mikrosekunden ausgegeben.

Sie folgen nicht einer strikt aufsteigenden Reihenfolge nach den konvertierten
Zeiten, da die von den ISR generierten Zyklenstempel zunächst
zwischengespeichert und erst später durch eine FreeRTOS-Task in einer frei
wählbaren Frequenz ausgegeben werden müssen. Da jedoch jeder Zyklenstempel in
Echtzeit ohne Verzögerung oder Overhead erzeugt wird, spiegelt die zugehörige
Zyklenzahl und somit die konvertierten Zeitpunkten in Mikrosekunden die
tatsächlichen Echtzeitaspekte des Systems korrekt wider. Daher ist eine strikt
geordnete Ausgabe nicht zwingend erforderlich.

\begin{code}
\begin{minted}{cpp}
IDLE 1 0        << mittels FreeRTOS-Task periodisch ausgegeben
profile 2 1     << mittels FreeRTOS-Task periodisch ausgegeben
w_ctrl 7413 1   << in Echtzeit ausgegeben
w_ctrl 7504 0   << in Echtzeit ausgegeben
odom 7951 1     << in Echtzeit ausgegeben
odom 7969 0     << in Echtzeit ausgegeben
profile 28 0    << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 29 1       << mittels FreeRTOS-Task periodisch ausgegeben
IDLE 332 0      << mittels FreeRTOS-Task periodisch ausgegeben
tsink 333 1     << mittels FreeRTOS-Task periodisch ausgegeben
tsink 336 0     << mittels FreeRTOS-Task periodisch ausgegeben
...
\end{minted}
    \captionof{listing}{Ausschnitt der Profiling-Daten}
\end{code}

Es wurde versucht, die parallele Ausgabe zu synchronisieren: Jeder Thread ruft
die Schreibfunktion der Senke mit einem atomar inkrementierten Zähler auf.
Dieser wird dann mit dem internen Zähler verglichen. Stimmen die Werte überein,
wird die Schreiboperation ausgeführt, andernfalls wird der Thread blockiert.
Dieser Versuch erwies sich als nicht erfolgreich, da die resultierende
Performance aufgrund des nicht-deterministischen Schedulings um die Hälfte sank.

Anschließend wurde versucht, alle Zyklenstempel zunächst in dem statischen
Puffer zwischenzuspeichern, um das Erzeugen und Ausgabe komplett voneinander zu
trennen. Mit diesem Ansatz konnte die Reihenfolge konsistent gehalten werden.

% \begin{code}
% \begin{minted}{cpp}
% uros 2 0
% profile 2 1
% profile 28 0
% ...
% w_ctrl 14031 1
% w_ctrl 14133 0
% \end{minted}
%     \captionof{listing}{Profiling-Daten in aufsteigender Reihenfolge}
% \end{code}
